## Операционные системы

### Предпосылки возникновения ОС

Большинство пользователей компьютера понимает, зачем нужна [**операционная система**](https://ru.wikipedia.org/wiki/Операционная_система#Функции) (ОС). Как правило, при покупке или загрузке из интернета какого-то приложения вы проверяете его системные требования. В них кроме требований к аппаратной части компьютера указана ОС, на которой приложение запускается. Получается, что ОС — это некоторая программная платформа, которая нужна для работы приложений. Но откуда взялось это требование? Почему нельзя просто купить компьютер и запустить на нём приложение вообще без ОС?

Эти вопросы кажутся бессмысленными только на первый взгляд. Подумайте сами: современные ОС универсальны и предлагают пользователю множество функций. Большинство из них каждому конкретному пользователю просто не нужно. Но эти функции зачастую невозможно отключить. Для их обслуживания ОС активно использует ресурсы компьютера. В результате для полезной нагрузки системы, то есть приложений с которыми работает пользователь, ресурсов остаётся намного меньше. Это приводит к медленной работе, зависаниям и даже перезагрузкам компьютера.

Обратимся к истории, чтобы выяснить причины возникновения ОС. На самом деле первая ОС [GM-NAA I/O](https://ru.wikipedia.org/wiki/GM-NAA_I/O) появилась только в 1956 году для компьютера [IBM 704](https://ru.wikipedia.org/wiki/IBM_704). Все более ранние модели компьютеров обходились без ОС. Почему в них не возникало необходимости?

Основная причина заключается в быстродействии. Например, рассмотрим первый [**электромеханический компьютер**](http://chernykh.net/content/view/16/40/), сконструированный [Германом Холлеритом](https://ru.wikipedia.org/wiki/Холлерит,_Герман) в 1890 году. Этому компьютеру, получившему название табулятор, не требовалась ОС и [программы](https://ru.wikipedia.org/wiki/Компьютерная_программа) в современном смысле этого слова. Табулятор выполнял только ограниченный набор арифметических операций, который определялся его конструкцией. Данные для вычислений загружались с [**перфокарт**](https://ru.wikipedia.org/wiki/Перфокарта), которые представляли собой листки плотной бумаги с пробитыми отверстиями. Эти листки вручную подготавливались и укладывались в специальные приёмные устройства. Там они нанизывались на иглы и в местах отверстий происходило замыкание электрической цепи. Каждое замыкание приводило к увеличению механического счётчика, представлявшего собой вращающийся цилиндр. Результаты вычислений выводились на циферблаты, напоминавшие часы.

Иллюстрация 1-1 демонстрирует табулятор, построенный Германом Холлеритом.

{caption: "Иллюстрация 1-1. Табулятор Холлерита", height: "30%"}
![Табулятор Холлерита](images/GeneralInformation/tabulating-machine.jpg)

По современным меркам табулятор работал очень медленно. На это было несколько причин. Прежде всего данные для вычислений подготавливались вручную. Не было способа автоматически пробивать перфокарты. Далее загрузка перфокарт в компьютер также выполнялась вручную. Сам табулятор содержал большое количество механических частей: иглы для считывания данных, счётчики из вращающихся цилиндров, циферблаты для вывода результата. Вся эта механика работала медленно. На выполнение одной элементарной операции уходило время порядка одной секунды. Никакая автоматизация не могла бы ускорить эти процессы.

На смену табуляторам, работающим на вращающихся цилиндрах, пришли компьютеры, использующие [**реле**](https://ru.wikipedia.org/wiki/Реле). Реле — это механический элемент, который меняет своё состояние под воздействием электрического тока. Один из [первых релейных компьютеров](https://habr.com/ru/company/ua-hosting/blog/386247), называвшийся Z2, сконструировал немецкий инженер [Конрад Цузе](https://ru.wikipedia.org/wiki/Цузе,_Конрад) в 1939 году. Затем этот компьютер был усовершенствован в 1941 году и получил название Z3. Переход на реле позволил сократить время на выполнение каждой элементарной операции с секунды до миллисекунд.

Кроме возросшей скорости вычислений, компьютеры Цузе отличала ещё одна особенность. В них появилось понятие программы. Теперь с помощью перфокарт вводились не исходные данные задачи, а [**алгоритмы**](https://ru.wikipedia.org/wiki/Алгоритм) по которым она решалась. Для ввода данных использовалась клавиатура, отдалённо напоминающая печатную машинку. Такие компьютеры стали называться [**программируемыми**](https://ru.wikipedia.org/wiki/Компьютер_общего_назначения) или универсальными.

I> Алгоритмом называется конечная последовательность инструкций для выполнения какого-либо вычисления или решения задачи.

Появление программируемых компьютеров стало важной вехой в развитии вычислительной техники. До этого момента машины выполняли только узкоспециализированные задачи. Это было слишком дорого и неэффективно. По этой причине многие инвесторы избегали вкладывать деньги в проекты по конструированию новых компьютеров. Эти проекты ограничивались только военными разработками в годы Второй мировой войны.

Следующим большим шагом стало создание компьютера [**ENIAC**](https://ru.wikipedia.org/wiki/ЭНИАК) (см. иллюстрацию 1-2) в 1946 году [Джоном Эккертом](https://ru.wikipedia.org/wiki/Эккерт,_Джон_Преспер) и [Джоном Мокли](https://ru.wikipedia.org/wiki/Мокли,_Джон). В качестве рабочих элементов в нём использовались не реле, а [**электровакуумные лампы**](https://ru.wikipedia.org/wiki/Электронная_лампа). Таким образом электромеханические компоненты с большим временем отклика были заменены на более быстрые электронные. Это позволило на порядок увеличить быстродействие компьютера и добиться выполнения одной элементарной операции за 200 микросекунд.

{caption: "Иллюстрация 1-2. ENIAC", height: "30%"}
![ENIAC](images/GeneralInformation/eniac.jpg)

В среде инженеров долго сохранялось скептическое отношение к электровакуумным лампам. Они были известны своей низкой надёжностью и высоким энергопотреблением. Никто не верил, что сконструированная на них машина вообще сможет работать. В ENIAC использовалось около 18 000 ламп. Они часто выходили из строя, но между их отказами компьютер успешно справлялся с вычислениями. ENIAC стал положительным примером использования ламп, который переубедил многих конструкторов.

ENIAC был программируемым компьютером. В нём алгоритм вычислений задавался с помощью комбинации переключателей и перемычек на коммутационных панелях. Такое программирование требовало значительного времени и одновременной работы нескольких человек. На иллюстрации 1-3 изображена одна из панелей для программирования ENIAC.

{caption: "Иллюстрация 1-3. Панель программирования ENIAC", height: "30%"}
![Панель программирования ENIAC](images/GeneralInformation/eniac-programming.jpg)

Для ввода исходных данных и вывода результатов использовались перфокарты, как и в предыдущих моделях компьютеров. Иногда перфокарты использовались для хранения промежуточных расчётов. Если исходная задача из-за своей сложности не могла быть решена сразу, она разбивалась на несколько подзадач. После выполнения каждой из них результаты выгружались на перфокартах, а компьютер перепрограммировался. Затем перфокарты загружались обратно в качестве входных данных.

Опыт эксплуатации ENIAC показал, что производительность компьютера ограничивают все механические операции: ручное перепрограммирование с помощью переключателей и перемычек, чтение и пробивание перфокарт. Несмотря на то, что сам компьютер обладал небывалой по тем временам производительность, для решения конкретной задачи на нём требовалось значительное время. Большую часть этого времени компьютер простаивал, ожидая программы или входных данных. Эти выводы послужили толчком для развития новых средств ввода данных и программ, а также вывода результатов вычислений.

Вычислительная мощность компьютеров увеличилась на порядок после перехода с электровакуумных ламп на [**транзисторы**](https://ru.wikipedia.org/wiki/Транзистор). Вместе с усовершенствованными средствами ввода-вывода это привело к более интенсивной эксплуатации компьютеров и их частому перепрограммированию. К этому времени вычислительные машины распространились за пределы военных проектов и стали использоваться крупными банками и корпорациями. В результате возрасло число и разнообразие запускаемых на них программ.

Часто программы исполнялись друг за другом без задержек, чтобы избежать простоя оборудования. Для автоматизации загрузки программ и вывода их результатов потребовались специальные решения. Именно для управления выполнением программ и была разработана первая ОС GM-NAA I/O.

Интенсивное использование компьютеров и разнообразие программ поставило не только задачу управления их исполнением. Дело в том, что функции компьютера определялись загружаемой в него программой. Например, если она включала в себя код для управления устройствами ввода-вывода, они были доступны. В противном случае эти устройства не работали. Для конкретной модели компьютера подключенное к нему оборудование менялось редко. Поэтому код для работы с ним копировался. Он кочевал из одной программы в другую, занимая лишнее место на устройствах хранения. Со временем этот код стали выносить в отдельную служебную программу, которая загружалась вместе с основной. Постепенно эти служебные программы вошли в состав первых ОС.

Вернёмся к нашему вопросу о необходимости операционных систем. Мы выяснили, что приложения могут работать и без них. Такие программы используются и сегодня. Например, это [**утилиты**](https://ru.wikipedia.org/wiki/Утилита) проверки памяти и разбивки диска, а также некоторые антивирусы. Однако, разработка таких программ требует больше времени и сил. В них приходится включать код для поддержки оборудования, который обычно предоставляется ОС. Чтобы уменьшить объём работы, а значит ускорить выпуск программы, разработчики активно используют возможности ОС.

### Возможности ОС

Почему мы начали изучение программирования с рассмотрения ОС? Иллюстрация 1-4 демонстрирует схему взаимодействия ОС с [**прикладными программами**](https://ru.wikipedia.org/wiki/Прикладное_программное_обеспечение) и [**аппаратным обеспечением**](https://ru.wikipedia.org/wiki/Аппаратное_обеспечение). Прикладные программы — это приложения, которые решают задачи пользователя (например, текстовый редактор, калькулятор, браузер). Под аппаратным обеспечением подразумеваются все электронные и механические компоненты компьютера (например, клавиатура, монитор, центральный процессор, видеокарта).

{caption: "Иллюстрация 1-4. Схема взаимодействия ОС с программами и аппаратным обеспечением", height: "50%"}
![Схема взаимодействия ОС](images/GeneralInformation/operating-system.png)

Согласно схеме, приложения получают доступ к аппаратным ресурсам не напрямую, а через [**системные библиотеки**](https://ru.wikipedia.org/wiki/Библиотека_(программирование)) ОС. Этот доступ предоставляется по определённым правилам. Программа работает только с теми возможностям устройств, которые поддерживаются ОС. Правила работы с устройствами определены в [**интерфейсе прикладного программирования**]((https://ru.wikipedia.org/wiki/API)), также известном как API (Application Programming Interface), который предоставляется системными библиотеками. Интерфейс — это набор соглашений о взаимодействии компонентов информационной системы. Как правило, интерфейсы описываются стандартами. Благодаря им, гарантируется совместимость компонентов системы.

API интерфейс описывает следующие аспекты взаимодействия программ и ОС:

1. Какая операция будет выполнена при вызове конкретной функции ОС?

2. Какие данные следует переданы ей на вход?

3. Какие данные функция вернёт в качестве результата?

Следование интерфейсу крайне важно как со стороны ОС, так и со стороны приложений. Это гарантирует их совместимость на уровне текущих версий и будущих модификаций. Без хорошо документированного, стандартизированного интерфейса такая совместимость была бы невозможна.

Мы уже выяснили, что приложения могут работать без ОС. Однако, она предлагает готовые решения для взаимодействия с аппаратными ресурсами компьютера, которые в противном случае пришлось бы решать разработчикам приложений. Это огромная работа. Тем более если учесть разнообразие комплектующих современных компьютеров. Все модели устройств (например, видеокарт) должны поддерживаться, иначе программа не сможет стабильно работать у всех пользователей.

Выясним, какие возможности предоставляет современная ОС через свой API интерфейс.

Все электронные и механические компоненты компьютера (аппаратное обеспечение), можно рассматривать как некоторые ресурсы, необходимые для вычислений. Именно с помощью этих компонентов выполняются программы пользователей.

Интерфейс отражает не только список возможностей оборудования, которыми может воспользоваться программа. Также он устанавливает порядок взаимодействия между несколькими программами и оборудованием. Рассмотрим пример.

Две программы не могут одновременно записывать данные на [жёсткий диск](https://ru.wikipedia.org/wiki/Жёсткий_диск#Технологии_записи_данных) в одну и ту же область. Во-первых, запись выполняется единственной магнитной головкой жёсткого диска. Во-вторых, данные, записанные первым приложением, будут затёрты данными второго. Поэтому одновременные запросы программ на запись должны блокироваться или помещаться в очередь и исполняться друг за другом. За эти механизмы отвечает ОС, а точнее её [**ядро**](https://ru.wikipedia.org/wiki/Ядро_операционной_системы) (см. иллюстрацию 1-4), в котором реализована [**файловая система**](https://ru.wikipedia.org/wiki/Файловая_система). Похожим образом ОС упорядочивает доступ ко всем [**периферийным**](https://ru.wikipedia.org/wiki/Периферийное_устройство) и внутренним устройствам компьютера. Этот доступ предоставляется через специальные программы, называемые [**драйверами устройств**](https://ru.wikipedia.org/wiki/Драйвер) (см. иллюстрацию 1-4).

Что такое периферийные устройства, и чем они отличаются от внутренних? К периферийным относятся все устройства, отвечающие за ввод и вывод информации, а также за её постоянное хранение. Например, клавиатура, мышь, микрофон, монитор, колонки, жёсткий диск. Внутренние устройства отвечают за обработку информации, то есть непосредственное исполнение программ. К ним относятся [**центральный процессор**](https://ru.wikipedia.org/wiki/Центральный_процессор) (central processing unit, CPU), [**оперативную память**](https://ru.wikipedia.org/wiki/Оперативная_память) (random-access memory, RAM), [**видеокарту**](https://ru.wikipedia.org/wiki/Видеокарта) (graphics processing unit, GPU).

Интерфейс доступа к аппаратным ресурсам — это не единственное, что предоставляет ОС. Кроме аппаратных есть ещё и программные ресурсы ОС. Это тот самый повторяющийся код, ставший со временем служебными программами и оформленный впоследствии в системные библиотеки (см. иллюстрацию 1-4). Некоторые из них обслуживают устройства, но некоторые выполняют полезные операции над входными данными. Например, компонент Windows под названием [**интерфейс графических устройств**](https://ru.wikipedia.org/wiki/GDI) даёт приложениям возможность манипулировать графическими объектами. С их помощью разработчики могут создавать пользовательский интерфейс для своих программ. К программным ресурсам относятся все компоненты ОС, установленные на компьютере. Кроме них ОС может также предоставлять доступ к алгоритмам сторонних приложений или библиотек.

ОС не только управляет ресурсами, но и организует работу запущенных приложений. Прежде всего код приложения надо загрузить с [**устройства хранения информации**](https://ru.wikipedia.org/wiki/Компьютерная_память) (будь то перфокарта или жёсткий диск) и поместить в оперативную память компьютера. Эта процедура нетривиальная, поскольку надо также загрузить код всех сторонних библиотек, которые используются приложением во время работы. Процесс запуска и исполнения программы мы рассмотрим подробнее в следующем разделе.

Если ОС многопользовательская, она контролирует доступ к данным. Таким образом каждый пользователь может работать только со своими собственными файлами и каталогами.

Подведём итог. Современная ОС выполняет следующие функции:

1. Предоставляет и упорядочивает доступ к аппаратным ресурсам компьютера.

2. Предоставляет программные ресурсы в виде системных библиотек.

3. Запускает приложения, а также отвечает за ввод данных для них и вывод результата.

4. Организует взаимодействие приложений друг с другом.

5. Контролирует доступ пользователей к своим данным.

Изучив эти функции, внимательный читатель возможно догадался, что без ОС невозможно одновременное выполнение нескольких приложений. Ведь их разработчики не могут предусмотреть в каком сочетании программы будут выполняться. Только ОС имеет достаточно информации, чтобы эффективно распределить ресурсы компьютера в реальном времени.

### Современные ОС

Мы рассмотрели возможности ОС в общих чертах. Теперь с учётом наших новых знаний поговорим о современных ОС. Они отличаются друг от друга не столько предоставляемыми функциями, которые у всех почти одинаковы, сколько способами их реализации. Эти особенности реализации и решения, которые к ним привели, принято называть [**архитектурой**](https://ru.wikipedia.org/wiki/Архитектура_программного_обеспечения).

У всех современных ОС есть две важные особенности, которые во многом определяют их поведение и взаимодействие с пользователем. Речь идёт о многозадачности и графическом интерфейсе. Рассмотрим их подробнее.

#### Многозадачность

Подавляющее большинство современных ОС [**многозадачны**](https://ru.wikipedia.org/wiki/Многозадачность). Это означает, что они поддерживают одновременное исполнение нескольких программ. Почему это свойство оказалось важным? Ведь системы, обладающие этим свойством, вытеснили те, у которых его не было.

Задача увеличения эффективности использования компьютеров стояла очень остро в 1960-е годы. Тогда компьютеры стоили дорого и, следовательно, дорога была каждая минута их работы. Крупные компании и университеты, которые могли позволить себе купить мейнфрейм, считали неприемлемым любой его простой.

Ранние операционные системы позволяли последовательно исполнять программы друг за другом без задержек. Это экономило время, необходимое на переключение компьютера с одной задачи на другую. В таких системах несколько программ и входные данные для них подготавливались заранее и записывались на устройство хранения (например, магнитную ленту). Эта лента подавалась на устройство чтения компьютера. Он последовательно исполнял программы и выводил их результаты на устройство вывода (например, принтер). Такой режим работы получил название [**пакетная обработка**](https://ru.wikipedia.org/wiki/Пакетное_задание) ([batch processing](https://en.wikipedia.org/wiki/Batch_processing)).

Пакетная обработка позволила более эффективно использовать время мейнфреймов. Она автоматизировала загрузку программ и частично исключила из этого процесса человека-оператора. Однако, у системы оставалось ещё одно [**узкое место**](https://ru.wikipedia.org/wiki/Узкое_место). Дело в том, что вычислительная мощность процессоров стала значительно превосходить скорость работы периферийных устройств. Это привело к простоям CPU.

I> Узкое место (bottleneck) — компонент или ресурс информационной системы, который ограничивает её общую производительность или пропускную способность.

Рассмотрим пример. Представьте, что мейнфрейм последовательно выполняет вычислительные программы. Данные для них считываются с магнитной ленты, а результаты печатаются на принтере. ОС загружает каждую программы и исполняет её инструкции, затем загружает следующую и так далее. Проблемы возникают на этапах чтения данных и печати результата. Время доступа к данным на магнитной ленте огромно в масштабах центрального процессора. Между двумя последовательными операциями чтения, он мог бы выполнить значительный объём вычислений. Но он этого не делает, поскольку все ресурсы компьютера используются только текущей программой, загруженной в память. То же самое происходит с выводом результатов расчётов на печать. Принтер, как чисто механическое устройство, работает очень медленно. Эта проблема простоя оборудования и привела к идее [**мультипрограммирования**](https://ru.wikipedia.org/wiki/Мультипрограммирование).

Суть мультипрограммирования заключается в том, что в память компьютера загружается сразу несколько программ. Первая из них начинает выполняться до тех пор, пока доступны все необходимые ей ресурсы. Как только какой-либо из ресурсов оказывается занят, её выполнение останавливается. Например, программе нужны данные, хранящиеся на жёстком диске. Пока контроллер диска выполняет их чтение, считается, что он занят и не может обработать следующий запрос. В этом случае ОС прекращает выполнение первой программы и переключается на вторую. Она в свою очередь исполняется до конца или до момента доступа к занятому ресурсу. После этого опять происходит переключение.

Мультипрограммирование стало ранним прототипом многозадачности, которая реализована во всех современных ОС. Мультипрограммирование отлично справлялось с режимом пакетной обработки. Однако, этот подход распределения нагрузки совершенно не подходит для систем, предусматривающих [**интерактивное взаимодействие**](https://ru.wikipedia.org/wiki/Интерактивность). В них каждое действие пользователя (например, нажатие клавиши) является событием, которое требует какой-то реакции со стороны системы (например, добавление нового символа в текстовый документ). Если применять мультипрограммирование, то система оказывается занята выполнением очередной задачи непредсказуемо долго. До тех пор пока текущая программа не выполнена до конца или ей не был запрошен занятый ресурс, переключения задачи не произойдёт и никакие действия пользователя не могут быть обработаны.

Проблема интерактивной работы с компьютером была решена с помощью многозадачности. Способ её реализации постепенно развивался и усложнялся. В современных ОС применяется [**вытесняющая многозадачность**](https://ru.wikipedia.org/wiki/Вытесняющая_многозадачность) с псевдопараллельной обработкой задач. Это означает, что ОС самостоятельно принимает решение о том, какая задача будет выполняться в данный момент времени. При этом выборе учитываются приоритеты задач. То есть более приоритетные будут получать аппаратные ресурсы чаще, чем низкоприоритетные. Механизм переключения задач реализован в ядре ОС и называется [**планировщиком задач**](https://ru.wikipedia.org/wiki/Диспетчер_операционной_системы).

Псевдопараллельность обработки означает, что в каждый момент времени выполняется одна-единственная задача. При этом переключение между задачами происходит настолько быстро, что пользователь этого не замечает. Ему кажется, что компьютер сразу реагирует на любое его действие. Однако на самом деле, каждая программа и компонент ОС получают аппаратные ресурсы в строго определённые моменты времени.

В случае компьютеров с несколькими процессорами или [многоядерными](https://ru.wikipedia.org/wiki/Ядро_микропроцессора) процессорами одновременно исполняются несколько программ. Грубо говоря, число одновременно выполняемых задач равно числу ядер всех процессоров компьютера. При этом принцип вытесняющей многозадачности с постоянным переключением задач сохраняется. Он позволяет наиболее эффективно сбалансировать нагрузку системы и обеспечить приемлемое время отклика на действия пользователя.

#### Интерфейс пользователя


Ещё одна общая черта современных ОС для [**персональных компьютеров**](https://ru.wikipedia.org/wiki/Персональный_компьютер) (ПК) и ноутбуков — это наличие [**графического интерфейса пользователя**](https://ru.wikipedia.org/wiki/Графический_интерфейс_пользователя) (graphical user interface или GUI). Благодаря ему пользователь может запускать прикладные приложения, а также манипулировать аппаратным обеспечением и программными ресурсами самой ОС. Рассмотрим подробнее историю его возникновения.

Интерактивный способ работы с компьютером стал известен широкому кругу пользователей только в 1960 году после анонса [мини-компьютера](https://en.wikipedia.org/wiki/Minicomputer) [PDP-1](https://ru.wikipedia.org/wiki/PDP-1) от фирмы [Digital Equipment Corporation](https://ru.wikipedia.org/wiki/Digital_Equipment_Corporation). Может быть не совсем понятна причина, по которой конструкторы и пользователи компьютеров вообще заинтересовались интерактивностью. В 1950-е годы на рынке мейнфреймов доминировали компьютеры от IBM. Все они работали в режиме пакетной обработки и успешно справлялись с вычислительными задачами. Их операционные системы с поддержкой мультипрограммирования позволяли балансировать нагрузку и обеспечивали хорошую производительность.

Идея интерактивной работы с компьютером возникла в рамках военного проекта SAGE, выполнявшегося по заказу ВВС США. Его целью была разработка автоматизированной системы ПВО для обнаружения советских бомбардировщиков. Проблема, которую решали конструкторы, заключалась в обработке данных с радаров. Эти данные выводились человеку-оператору, который в режиме реального времени должен был отдавать команды системе ПВО. Для решения этой задачи требовались новые методы работы с компьютером. Существовавшие в то время подходы (наподобие пакетной обработки) не удовлетворяли требованиям проекта, поскольку система ПВО должна была реагировать максимально быстро. В результате проекта SAGE был сконструирован первый интерактивный компьютер [AN/FSQ-7](https://en.wikipedia.org/wiki/AN/FSQ-7_Combat_Direction_Central) (см иллюстрацию 1-5). В нём данные о воздушных угрозах выводились на [**электронно-лучевой монитор**](https://ru.wikipedia.org/wiki/Кинескоп), а для ввода команд использовалось [**световое перо**](https://ru.wikipedia.org/wiki/Световое_перо).

{caption: "Иллюстрация 1-5. Компьютер AN/FSQ-7"}
![Компьютер AN/FSQ-7](images/GeneralInformation/AN-FSQ-7.jpg)

Метод интерактивной работы с компьютером стал известен в научных кругах и быстро набрал популярность. Главная проблема пакетной обработки заключается в длительности разработки и отладки программ. После подготовки алгоритма и записи его на устройство хранения, программисту приходилось часами ждать результатов его исполнения на мейнфрейме. Компьютеры в то время были очень загружены работой и все поступающие программы обрабатывались в порядке очереди. В случае обнаружения ошибки в программе, алгоритм надо было исправить, записать на устройство и снова ждать. Таким образом до момента исправления всех ошибок и получения нужного результата могли пройти дни.

Интерактивный режим позволял программисту запускать программу и сразу же видеть на экране её результат. Благодаря этому, продуктивность работы с компьютером значительно возрастала. Можно было за несколько часов добиться результатов, на которые раньше требовались дни.

Появление интерактивного режима привело к новым задачам. Прежде всего понадобился новый способ балансирования нагрузки, который бы позволил добиться приемлемого времени отклика системы на действия пользователя. Как мы уже знаем, многозадачность новых ОС решила эту проблему.

На самом деле интерактивная работа возможна и на однозадачных ОС (например, [MS-DOS](https://ru.wikipedia.org/wiki/DOS)). Однако, такой режим стал целесообразен только с появлением относительно недорогих персональных компьютеров. Во времена дорогих мейнфреймов, ресурсы одного компьютера одновременно предоставлялись нескольким пользователям. Каждый из них запускал свои программы, которые выполнялись параллельно. Такой режим работы получил название [**разделение времени**](https://ru.wikipedia.org/wiki/Разделение_времени) (time-sharing). Обеспечить интерактивную работу в этом режиме невозможно без многозадачности.

Другая проблема интерактивности заключалась в способе взаимодействия пользователя и компьютера. Как именно должны выглядеть и работать устройства ввода и вывода информации, чтобы ими было удобно пользоваться?

Прототипом первых пользовательских интерфейсов для компьютера стало устройство под названием [**телетайп**](https://ru.wikipedia.org/wiki/Телетайп) (teletype) (см. иллюстрацию 1-6). Оно представляет собой электромеханическую печатную машинку, подключённую с помощью проводов к другому такому же устройству. Ранние версии телетайпа использовались для передачи текстовых сообщений между двумя абонентами. Пользователь набирал текст на своём устройстве. Каждое нажатие клавиши передавалось на устройство получателя и распечатывалось в виде буквы на бумаге.

{caption: "Иллюстрация 1-6. Телетайп Model 33", height: "50%"}
![Телетайп Model 33](images/GeneralInformation/teletype.jpg)

Телетайпы стали применять для удалённого доступа к мейнфреймам. Такое устройство получило название [**терминал**](https://ru.wikipedia.org/wiki/Компьютерный_терминал). Пользователи набирали на клавиатуре команды и отправляли их на компьютер. Он их выполнял и отправлял результат обратно на терминал, который распечатывал полученные данные на бумаге. Позднее устройство печати заменили на монитор. В результате получился [**интерфейс командной строки**](https://ru.wikipedia.org/wiki/Интерфейс_командной_строки) (command-line interface или CLI). Принцип его работы напоминает классический телетайп — пользователь вводит команды одну за другой. Компьютер их последовательно исполняет и выводит на экран результат.

Пример современного интерфейса командной строки приведён на иллюстрации 1-7. На ней вы видите окно эмулятора терминала [Terminator](https://en.wikipedia.org/wiki/Terminator_(terminal_emulator)), в котором запущен интерпретатор командной строки Bash. В окне выведены результаты работы программ `ping` и `ls`.

{caption: "Иллюстрация 1-7. Интерфейс командной строки", height: "50%"}
![Интерфейс командной строки](images/GeneralInformation/cli.png)

Интерфейс командной строки активно применяется и сегодня. У него есть несколько преимуществ перед более привычным сегодня графическим интерфейсом. Главное преимущество CLI в том, что он не требователен к вычислительным ресурсам. Он может работать на низкопроизводительных компьютерах так же как и на более мощных без каких-либо ограничений. Если применять CLI для удалённого доступа к компьютеру, он не требователен к качеству канала связи и его пропускной способности. Даже с медленным соединением вы сможете отправлять и исполнять команды.

Основная проблема интерфейса командной строки заключается в сложности его освоения. Список всех доступных пользователю команд, как правило, достаточно большой. При этом каждая из них имеет различные входные параметры. Чтобы запомнить хотя бы наиболее часто используемые команды и их режимы работы, надо потратить немало времени.

Попытки решить проблему с наглядным представлением доступных команд и результатов их работы привели к созданию [**текстового интерфейса пользователя**](https://ru.wikipedia.org/wiki/Текстовый_интерфейс_пользователя) (textual user interface или TUI). В нём наряду с буквенными и цифровыми символами используется [**псевдографика**](https://ru.wikipedia.org/wiki/Псевдографика). Под псевдографикой понимают специальные символы, с помощью которых отображаются графические примитивы (например, линии, прямоугольники, треугольники и т.д.). Пример текстового интерфейса пользователя приведён на иллюстрации 1-8. На ней вы видите вывод программы `htop` со статистикой использования системных ресурсов.

{caption: "Иллюстрация 1-8. Текстовый интерфейс пользователя", height: "50%"}
![Текстовый интерфейс пользователя](images/GeneralInformation/tui.png)

Дальнейшее увеличение мощности компьютеров позволило заменить псевдографику на реальные графические элементы такие как окна, иконки, кнопки и т.д. В результате этого возник полноценный графический интерфейс, который применяется в современных ОС.

Графический интерфейс ОС Windows приведён на иллюстрации 1-9. На ней вы видите скриншот рабочего стола с развёрнутыми окнами трёх одновременно работающих приложений: Проводника, Блокнота и Калькулятора.

{caption: "Иллюстрация 1-9. Графический интерфейс пользователя"}
![Графический интерфейс пользователя](images/GeneralInformation/gui.png)

Графический интерфейс был разработан для мини-компьютера [Xerox Alto](https://ru.wikipedia.org/wiki/Xerox_Alto) (см. иллюстрацию 1-10) в 1973 году в исследовательском центре [Xerox PARC](https://ru.wikipedia.org/wiki/Xerox_PARC). Однако, он не получил широко распространения вплоть до 1980-х годов. Причиной этого стали высокие требования GUI к памяти и производительности компьютеров. Первый ПК Lisa с графическим интерфейсом был выпущен на рынок компанией Apple только в 1983 году.

{caption: "Иллюстрация 1-10. Мини-компьютер Xerox Alto", height: "50%"}
![Мини-компьютер Xerox Alto](images/GeneralInformation/xerox-alto.jpg)

#### Семейства ОС

Сегодня на рынке персональных компьютеров доминируют три основных семейства ОС:

* [Windows](https://ru.wikipedia.org/wiki/Windows)
* [Linux](https://ru.wikipedia.org/wiki/Linux)
* [macOS](https://ru.wikipedia.org/wiki/MacOS)

Может возникнуть вопрос: что именно подразумевается под семейством ОС? Этот термин означает ряд версий ОС, которые следуют одним и тем же архитектурным решениям, а также сохраняют некоторые особенности реализации тех или иных функций.

Почему разработчики каждой ОС предпочитают придерживаться одной и той же архитектуры, а не предлагают что-то принципиально новое в следующих версиях? На самом деле изменения в современных ОС происходят, но очень постепенно и медленно. Причина этого в так называемой [**обратной совместимости**](https://ru.wikipedia.org/wiki/Обратная_совместимость). Эта совместимость предполагает наличие некоторых старых функций в новой версии ОС. Они нужны для корректной работы написанных ранее программ. На первый взгляд это требование может показаться совершенно неважным. Но на самом деле это серьёзное ограничение при разработке программного обеспечения. Давайте разберёмся, почему это так.

Представьте, что вы разработали программу для ОС Windows и продаёте её. Иногда в ней обнаруживаются ошибки, которые вы успешно исправляете. Время от времени вы добавляете в неё новые функции. Теперь представьте, что выходит новая версия Windows, на которой ваша программа перестаёт работать. У пользователей есть два решения: ждать от вас новой версии программы, совместимой с ОС, или отказаться от перехода на новую версию Windows. Теперь предположим, что новая версия ОС принципиально отличается от предыдущей. Это значит, что вам придётся переписать вашу программу буквально с нуля. Посчитайте всё время, которое вы уже потратили на исправление ошибок и добавление новых функций. Эту работу в полном объёме придётся повторить. Скорее всего вы откажетесь от этой идеи и предложите пользователям оставаться на старой версии Windows. Теперь представьте, что таких программ как ваша очень много. Их разработчики придут к тому же решению, что и вы. В результате новая версия Windows окажется никому не нужна. В этом и заключается проблема обратной совместимости. Именно поэтому и существуют семейства ОС.

Влияние приложений, доступных под конкретную ОС, сложно переоценить. Например, успех ОС Windows и персональных компьютеров от IBM во многом обусловлен табличным процессором [Lotus 1-2-3](https://ru.wikipedia.org/wiki/Lotus_1-2-3). Он был так называемым [**killer application**](https://ru.wikipedia.org/wiki/Killer_application) (букв. убойное приложение), ради запуска которого пользователи были готовы покупать и IBM ПК, и Windows. Аналогично табличный процессор [VisiCalc](https://ru.wikipedia.org/wiki/VisiCalc) способствовал распространению компьютеров [Apple II](https://ru.wikipedia.org/wiki/Apple_II), а бесплатные компиляторы языков C, Fortran и Pascal подогрели интерес к Unix в университетских кругах. За каждой из трёх ОС, доминирующих сегодня, стоит какое-то killer application. Далее их распространению способствовал [сетевой эффект](https://ru.wikipedia.org/wiki/Сетевой_эффект), когда разработчики программ выбирали в качестве целевой платформы именно ту ОС, которая уже была установлена у большинства пользователей.

Вернёмся к нашему списку семейств ОС. Windows и Linux примечательны тем, что не привязаны к конкретной аппаратной платформе. Это значит, что купив любой персональный компьютер или ноутбук, вы без особых трудностей сможете установить на него эти ОС. macOS в отличие от них рассчитана на запуск только на устройствах от Apple. Чтобы установить macOS на другую аппаратную платформу, вам потребуются её неофициальная [модифицированная версия](https://ru.wikipedia.org/wiki/OSx86). Совместимость с аппаратной платформой — это хороший пример одного из архитектурных решений. Но таких решений много, и все вместе они формируют особенности каждого семейства.

Неудивительно, что ОС во многом определяет инфраструктуру, доступную программисту. Она диктует не только инструменты разработки, такие как IDE, компилятор, система сборки, но и некоторые архитектурные решения самих запускаемых на ней приложений. Можно говорить о некоторой сложившейся культуре написания программ под конкретную ОС. Это очень важный момент, который следует всегда учитывать: под разные ОС программы принято разрабатывать по-разному.

Рассмотрим различие этих культур подробнее на примере Windows и Linux.

#### Windows

Как вам известно, Windows — это [проприетарная](https://ru.wikipedia.org/wiki/Проприетарное_программное_обеспечение) ОС. Это означает, что все её исходные коды закрыты для постороннего изучения и модификации. Вы не сможете законным способом узнать о ней больше, чем разработчики посчитают нужным вам сообщить. Чтобы установить Windows на свой компьютер, вам надо купить её у компании Microsoft. Однако, в большинстве случаев эта ОС уже предустановлена на новые компьютеры и ноутбуки, а её цена включена в стоимость устройства.

Обратите внимание, что целевой платформой Windows были и остаются относительно дешёвые персональные компьютеры. Многие могут позволить себе купить такое устройство. Следовательно, рынок потенциальных пользователей огромен. Microsoft стремится всеми силами сохранить конкурентное преимущество на этом рынке. Компания опасается появления аналогов своей ОС с такими же возможностями. Именно поэтому Microsoft заботится о защите своей интеллектуальной собственности не только техническими, но и юридическими путями. Строго говоря, пользовательское соглашение запрещает вам исследовать внутреннее устройство ОС.

За всё время существования семейства ОС Windows под него было написано очень много прикладных программ. Первые из них (например, пакет офисных приложений [Microsoft Office](https://ru.wikipedia.org/wiki/Microsoft_Office) или [стандартные приложения Windows](https://ru.wikipedia.org/wiki/Категория:Стандартные_приложения_Windows)) создавались самой компанией Microsoft. Для сторонних разработчиков они послужили в некотором роде образцом для подражания. Очевидно, что Microsoft при разработке своих приложений придерживалась того же принципа закрытости, что и при разработке ОС: исходные коды недоступны конечным пользователям, форматы данных недокументированны, сторонние утилиты не могут получить доступа к возможностям приложений. Опять же все эти решения были продиктованы заботой о защите интеллектуальной собственности компании от конкурентов.

Сторонние разработчики программ последовали примеру Microsoft и зачастую стали придерживаться той же философии закрытости. Большинство получившихся приложений самодостаточны и независимы друг от друга. Форматы их данных, как правило, закодированы и недокументированны.

Если вы опытный пользователь компьютера, вы легко сможете представить себе типичное Windows приложение. Оно представляет собой окно с такими [элементами интерфейса](https://ru.wikipedia.org/wiki/Элемент_интерфейса), как кнопки, поля ввода, вкладки и т.д. Через этот интерфейс пользователь манипулирует каким-то данными (например, текстом, изображением или звуковой записью). Результат работы сохраняется на жёсткий диск компьютера и может быть повторно загружен в том же самом приложении. Очень велика вероятность, что если вы напишете собственную Windows-программу, она будет работать похожим образом. Именно такая преемственность решений и имеется ввиду, когда мы говорим о сложившейся культуре разработки под конкретную ОС.

#### Linux

Linux является идейным наследником ОС [Unix](https://ru.wikipedia.org/wiki/Unix) и следует её [**спецификациям**](https://ru.wikipedia.org/wiki/Спецификация). Спецификация — это документ с требованиями к системе, который также определяет её поведение и внутреннее устройство. Получается, Linux заимствовал многие идеи и решения Unix, что в результате привело к похожему поведению.

Сама Unix возникла в конце 1960-х годов. Она создавалась как хобби-проект двумя инженерами компании Bell Labs: [Кеном Томпсоном](https://ru.wikipedia.org/wiki/Томпсон,_Кен) и [Деннисом Ритчи](https://ru.wikipedia.org/wiki/Ритчи,_Деннис). Они участвовали в крупном проекте компании по разработке ОС [**Multics**](https://ru.wikipedia.org/wiki/Multics) для нового мейнфрейма GE-645 (см. иллюстрацию 1-11) от компании General Electric. Кроме Bell Labs и General Electric над проектом также работал Массачусетский Технологический Институт (MIT).

{caption: "Иллюстрация 1-11. Мэйнфрейм модели GE-645", height: "30%"}
![Мэйнфрейм модели GE-645](images/GeneralInformation/ge-645.jpg)

В ОС Multics планировалось реализовать много инновационных идей. Одной из её ключевых особенностей было разделение времени. Как вы помните, это означает, что с одним мейнфреймом одновременно может работать несколько пользователей. При этом вычислительные ресурсы компьютера разделяются между ними с помощью многозадачности.

Разработка Multics затягивалась и Bell Labs решила выйти из проекта. Однако многие инженеры компании, работавшие над ним, хотели продолжать работу. Кен Томпсон решил создать собственную ОС для компьютера GE-645. Для этого он начал писать ядро и продублировал некоторые механизмы Multics. Однако, General Electric потребовала вернуть им дорогой мейнфрйем, и Кен Томпсон остался без аппаратной платформы для разработки.

Параллельно с работой над аналогом Multics Кен писал компьютерную игру [Space Travel](https://ru.wikipedia.org/wiki/Space_Travel). Она запускалась на мейнфрейме General Electric прошлого поколения GE-635, работающим под управлением ОС [GECOS](https://ru.wikipedia.org/wiki/GCOS). Этот компьютер представлял собой шкафы с электроникой и стоили порядка 7 500 000$. Его вычислительные ресурсы активно использовались для нужд компании и были постоянно заняты. Поэтому Кен решил портировать свою игру на относительно недорогой и реже используемый коллегами мини-компьютер [PDP-7](https://ru.wikipedia.org/wiki/PDP-7) (см. иллюстрацию 1-12) стоимостью порядка 72 000$. Проблема была в том, что игра использовала возможности ОС GECOS, которые были недоступны на PDP-7. Поэтому Кену и присоединившемуся к нему Деннису пришлось реализовать несколько библиотек и систем, которые впоследствии развились в Unix.

{caption: "Иллюстрация 1-12. Мини-компьютер PDP-7", height: "30%"}
![Мини-компьютер PDP-7](images/GeneralInformation/pdp-7.jpg)

Очевидно, в своём проекте разработчики Unix не заботились о защите интеллектуальной собственности, поскольку не собирались продавать свою ОС. Она разрабатывалась для собственных нужд и распространялась с открытым исходным кодом, доступным для изучения и модификации любым желающим. Изначально круг пользователей ограничивался сотрудниками компании Bell Labs. Позднее AT&T, которой принадлежала Bell Labs, предоставила исходный код Unix высшим учебным заведениям США. Таким образом развитие ОС продолжилось в университетских кругах.

Linux была создана в 1991 году [Линусом Торвальдсом](https://ru.wikipedia.org/wiki/Торвальдс,_Линус) во время его обучения в Хельсинкском университете. Линус решал чисто практическую проблему: в то время персональные компьютеры не имели полноценной Unix-совместимой ОС. В университете студенты выполняли учебные задания на миникомпьютере MicroVAX под управлением Unix, но дома у них не было оборудования, подходящего для её запуска. Единственной альтернативой Unix была ОС [Minix](https://ru.wikipedia.org/wiki/Minix), разработанная Эндрю Таненбаумом в 1987 году для персональных компьютеров IBM с процессорами Intel 80268. Но эта ОС разрабатывалась для учебных целей, и поэтому Эндрю отказывался вносить в неё изменения для поддержки более современных компьютеров. Эти изменения неизбежно привели бы к усложнению системы и сделали бы её непригодной для обучения студентов.

Линус задался целью написать Unix-совместимую ОС для своего нового компьютера IBM с процессором Intel 80386. Её прототипом стала учебная ОС Minix. Как и у создателей Unix, у него не было коммерческих интересов, связанных с продажей результата своего труда. Он разрабатывал систему для собственных нужд. Поэтому его ОС стала бесплатной и свободно распространялась с исходным кодом через интернет.

На самом деле Linux — это не более чем ядро ОС, предоставляющее функции для работы с памятью, файловой системой, периферийными устройствами, а также управлением процессорным временем. Большинство функций системы были доступны через свободные [пользовательские компоненты GNU](https://ru.wikipedia.org/wiki/Проект_GNU), которые Линус включил в [дистрибутив](https://ru.wikipedia.org/wiki/Дистрибутив_Linux) своей ОС.

Изначально у Linux, как у и Unix, не было графической подсистемы. Все приложения пользователь запускал из командной строки. Только некоторые сложные приложения имели текстовый интерфейс. Со временем в Linux появилась оконная система [X Window System](https://ru.wikipedia.org/wiki/X_Window_System), а вместе с ней и приложения с графическим интерфейсом, более привычные пользователям Windows.

Инфраструктура, в которой возник и развивался Unix (а позднее и Linux), во многом определила культуру написания приложений. В ней предпочтение отдаётся узкоспециализированным утилитам командной строки, которые выполняют только одну конкретную задачу, но делают это хорошо. Эти утилиты выдают результат своей работы в открытом формате данных (как правило [текстовом](https://ru.wikipedia.org/wiki/Текстовые_данные)). Их исходный код всегда доступен для изучения и модификации.

Сложившаяся на сегодняшний день культура Linux значительно отличается от стандартов разработки, принятых в Windows. В Windows каждое приложение монолитно и самостоятельно выполняет все необходимые для своей работы задачи. Оно не полагается на сторонние утилиты, которые могут оказаться платными или недоступными для пользователя по какой-то причине. Разработчик должен рассчитывать только на себя. Он не может требовать от пользователя купить что-то дополнительное для работы своего приложения. В Linux же подавляющее большинство утилит бесплатны, взаимозаменяемы и легко доступны через интернет. Поэтому вполне естественно, что какое-то приложение потребует загрузить и установить недостающие ему системные компоненты или другое приложение.

Даже монолитные графические приложения в Linux очень часто имеют дополнительный интерфейс командной строки. Таким образом они органично вписываются в экосистему и легко интегрируются с другими утилитами и приложениями.

Когда сложный вычислительный процесс строится на использовании набора отдельных узкоспециализированных приложений, становится насущным вопрос написания сценариев, по которому они должны выполняться. Именно для этой задачи была создана [командная оболочка](https://ru.wikipedia.org/wiki/Командная_оболочка_Unix) [Bourne shell](https://ru.wikipedia.org/wiki/Bourne_shell) и её потомок [Bash](https://ru.wikipedia.org/wiki/Bash). В этой книге мы будем работать именно с Bash.

Стоит заметить, что нельзя отдать однозначное предпочтение культуре Linux перед Windows. Хоть их сравнение и служит поводом для бесконечных споров. Каждая из них имеет свои достоинства и недостатки. Например, широко распространённые в Windows монолитные приложения лучше справляются с задачами, требующими интенсивных расчётов. При комбинации узкоспециализированных Linux-утилит в этом случае возникают накладные расходы, связанные с их запуском и передачей данных между ними. В результате выполнение задачи требует больше времени.

I> Подробнее о культуре разработки в Unix вы можете узнать из книги [Эрика Реймонда "Искусство программирования в Unix"](https://ru.wikipedia.org/wiki/Философия_Unix#Реймонд:_Искусство_программирования_в_Unix).