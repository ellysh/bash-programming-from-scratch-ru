## Операционные системы

### Предпосылки возникновения ОС

Большинство пользователей компьютера понимает, зачем нужна [**операционная система**](https://ru.wikipedia.org/wiki/Операционная_система#Функции) (ОС). Покупая или загружая из интернета приложение, вы проверяете его системные требования. В них указаны минимальные параметры аппаратной части компьютера. Кроме этого в требованиях указана ОС.

Получается, что ОС — это программная платформа на которой работают приложения. Но откуда взялось это требование? Почему нельзя просто купить компьютер и запустить на нём приложение без ОС?

Эти вопросы кажутся бессмысленными только на первый взгляд. Подумайте сами: современные ОС универсальны и предлагают пользователю множество функций. Большинство из них каждому конкретному пользователю не нужно. Но эти функции зачастую невозможно отключить. Для их обслуживания ОС активно использует ресурсы компьютера. В результате приложениям пользователя достаётся меньше ресурсов. Из-за этого они работают медленно и зависают.

Обратимся к истории, чтобы выяснить назначение ОС. Первая коммерческая ОС [GM-NAA I/O](https://ru.wikipedia.org/wiki/GM-NAA_I/O) появилась только в 1956 году для компьютера [IBM 704](https://ru.wikipedia.org/wiki/IBM_704). Все ранние модели компьютеров обходились без ОС. Почему в них не было необходимости?

Главная причина заключается в быстродействии. Для примера рассмотрим первый [**электромеханический компьютер**](http://chernykh.net/content/view/16/40/). Его сконструировал [Герман Холлерит](https://ru.wikipedia.org/wiki/Холлерит,_Герман) в 1890 году. Компьютер получил название табулятор. Для работы ему не нужна ОС и [программы](https://ru.wikipedia.org/wiki/Компьютерная_программа) в современном смысле этих терминов. Табулятор выполняет ограниченный набор арифметических операций. Эти операции определяет конструкция компьютера. Данные для вычислений загружаются с [**перфокарт**](https://ru.wikipedia.org/wiki/Перфокарта). Перфокарты представляют собой листки плотной бумаги с пробитыми отверстиями. Оператор компьютера вручную подготавливает и укладывает эти листки в специальные приёмные устройства. Там они нанизываются на иглы. В местах отверстий иглы соприкасаются и электрическая цепь замыкается. Каждое замыкание увеличивает механический счётчик. Счётчиком служит вращающийся цилиндр. Результаты вычислений выводятся на циферблаты, напоминающие часы.

Иллюстрация 1-1 демонстрирует табулятор, построенный Германом Холлеритом.

{caption: "Иллюстрация 1-1. Табулятор Холлерита", height: "30%"}
![Табулятор Холлерита](images/GeneralInformation/tabulating-machine.jpg)

По современным меркам вычисления на табуляторе выполняются очень медленно. Первая причина заключается в ручном обслуживании. Оператор должен самостоятельно пробить перфокарты. Во времена табулятора не было способа делать это автоматически. Далее надо загрузить перфокарты в приёмное устройства и выгрузить их по окончании работы. На эти действия уходило много времени.

Вторая причина медленной работы табулятора связана с конструкцией. Большая часть его деталей механическая: иглы для считывания данных, счётчики из вращающихся цилиндров, циферблаты для вывода результата. Вся эта механика работает медленно. Выполнение одной элементарной операции занимает порядка одной секунды. Никакая автоматизация не способна ускорить такой процесс вычисления.

Для вычислений табулятор использует вращающиеся цилиндры. Их заменили на [**реле**](https://ru.wikipedia.org/wiki/Реле) в компьютерах следующего поколения. Реле — это электромеханический элемент. Он меняет своё состояние под воздействием электрического тока.

Один из [первых релейных компьютеров](https://habr.com/ru/company/ua-hosting/blog/386247) Z2 сконструировал немецкий инженер [Конрад Цузе](https://ru.wikipedia.org/wiki/Цузе,_Конрад) в 1939 году. Этот компьютер был усовершенствован в 1941 году и получил название Z3. Переход на реле сократил время выполнения одной элементарной операции до нескольких миллисекунд.

Кроме возросшей скорости вычислений, компьютеры Цузе отличает ещё одна особенность. В них появилось понятие программы. Теперь на перфокартах пробивались не исходные данные задачи, а [**алгоритм**](https://ru.wikipedia.org/wiki/Алгоритм) её решения. Для ввода данных использовалась клавиатура. Её конструкция отдалённо напоминает печатную машинку.

I> Алгоритмом — это конечная последовательность инструкций для выполнения какого-либо вычисления или решения задачи.

Компьютеры с возможностью ввода алгоритмов стали известны как [**программируемые**](https://ru.wikipedia.org/wiki/Компьютер_общего_назначения) или универсальные.

Появление программируемых компьютеров стало важным шагом в развитии вычислительной техники. Машины предыдущих поколений выполняли только узкоспециализированные задачи. Их создание обходилось дорого и редко себя оправдывало. Поэтому проекты по конструированию компьютеров не привлекали инвесторов. Такие проекты ограничивались военными разработками в годы Второй мировой войны. Новые универсальные компьютеры заинтересовали бизнес.

Следующим шагом развития компьютеров стало создание [**ENIAC**](https://ru.wikipedia.org/wiki/ЭНИАК) (см. иллюстрацию 1-2). Его сконструировала группа инженеров под руководством [Джона Эккерта](https://ru.wikipedia.org/wiki/Эккерт,_Джон_Преспер) и [Джона Мокли](https://ru.wikipedia.org/wiki/Мокли,_Джон) в 1946 году. Его рабочими элементами стали не реле, а [**электровакуумные лампы**](https://ru.wikipedia.org/wiki/Электронная_лампа). То есть электромеханические компоненты с большим временем отклика заменили на более быстрые электронные. Это увеличило быстродействие компьютера на порядок. Время выполнения одной элементарной операции сократилось до 200 микросекунд.

{caption: "Иллюстрация 1-2. ENIAC", height: "30%"}
![ENIAC](images/GeneralInformation/eniac.jpg)

В 1940-е годы многие инженеры скептически относились к электровакуумным лампам. Они были не надёжны и потребляли много энергии. Мало кто верил, что сконструированная на них машина вообще сможет работать. ENIAC использовал около 18000 ламп. Они часто выходили из строя. Но между отказами компьютер успешно справлялся с вычислениями. ENIAC убедил многих конструкторов в перспективности ламп.

ENIAC — это программируемый компьютер. В нём алгоритм вычислений задаётся с помощью комбинации переключателей и перемычек на коммутационных панелях. Такое программирование требует много времени и сил. С ней может справиться только группа операторов. На иллюстрации 1-3 изображена одна из панелей для программирования ENIAC.

{caption: "Иллюстрация 1-3. Панель программирования ENIAC", height: "30%"}
![Панель программирования ENIAC](images/GeneralInformation/eniac-programming.jpg)

ENIAC использует перфокарты для ввода исходных данных и вывода результатов. Предыдущие модели компьютеров обрабатывали ввод-вывод аналогично. Но в ENIAC появилась новая возможность. Перфокарты могли хранить промежуточные расчёты. Если исходная задача не решалась сразу из-за высокой сложности, она разбивалась на несколько подзадач. После выполнения каждой подзадачи её результаты выгружались на перфокарты. Затем компьютер перепрограммировался. После этого перфокарты загружались обратно в качестве входных данных.

Опыт эксплуатации ENIAC показал, что производительность компьютера ограничивают все механические операции. Например, ручное перепрограммирование с помощью переключателей и перемычек, а также чтение и пробивание перфокарт. ENIAC обладал небывалой по тем временам производительностью. Но несмотря на это, прикладные задачи решались на нём медленно. Большую часть времени компьютер простаивал, ожидая программы или входных данных. Опыт работы с ENIAC привел к разработке новых средств ввода и вывода данных.

Следующий скачок производительности компьютеров произошёл после перехода с электровакуумных ламп на [**транзисторы**](https://ru.wikipedia.org/wiki/Транзистор). Вместе с усовершенствованными средствами ввода-вывода это привело к более интенсивной эксплуатации компьютеров и их частому перепрограммированию.

С приходом транзисторов вычислительные машины распространились за пределы военных проектов. Их стали использовать крупные банки и корпорации. В результате возросло число и разнообразие запускаемых программ.

Коммерческое использование компьютеров потребовало исключить простой оборудования. Любые задержки в исполнении программ приводили к финансовым потерям. В этом случае покупка компьютера не оправдывала себя.

Чтобы удовлетворить новым требованиям, требовались новые решения. Дольше всего компьютеры простаивали в ожидании переключения между программами. Идея автоматизировать этот процесс пришла к инженерам General Motors и North American Aviation. Они разработали первую операционную систему [**GM-NAA I/O**](https://ru.wikipedia.org/wiki/GM-NAA_I/O) в 1955 году. Эта ОС позволила выполнять программы друг за другом без помощи оператора.

Интенсивное использование компьютеров и разнообразие программ привело к ещё одной проблеме. Загруженная программа определяла доступные возможности аппаратуры. Например, если программа содержит код управления устройствами ввода-вывода, они доступны. В противном случае устройства не работают.

Компании покупали один компьютер и использовали его продолжительное время. При этом загружаемые программы менялись часто, но аппаратура оставалась неизменной. В результате код управления аппаратурой менялся редко. Программисты просто копировали его из одной программы в другую.

Постоянное копирование кода управления устройствами привело к идее создания служебной программы. Она загружалась в память компьютера вместе с основной программой и обеспечивала поддержку оборудования. Постепенно эти служебные программы вошли в состав первых ОС.

Вернёмся к нашему вопросу о необходимости операционных систем. Мы выяснили, что приложения могут работать и без них. Такие программы используются и сегодня. Например, это [**утилиты**](https://ru.wikipedia.org/wiki/Утилита) проверки памяти и разбивки диска, а также некоторые антивирусы. Однако, разработка таких программ требует больше времени и сил. В них приходится включать код для поддержки оборудования, который обычно предоставляет ОС. Разработчики предпочитают использовать возможности ОС. Это уменьшает объём работы и ускоряет выпуск программы.

Современные ОС очень сложны. Кроме поддержки оборудования и запуска программ, они предоставляют много других возможностей. Рассмотрим их подробнее.

### Возможности ОС

Почему мы начали изучать программирование с обсуждения операционных систем? Возможности ОС являются фундаментом для любой программы.

Иллюстрация 1-4 демонстрирует схему взаимодействия ОС с [**прикладными программами**](https://ru.wikipedia.org/wiki/Прикладное_программное_обеспечение) и [**аппаратным обеспечением**](https://ru.wikipedia.org/wiki/Аппаратное_обеспечение). Прикладные программы — это приложения, которые решают задачи пользователя. Примеры приложений: текстовый редактор, калькулятор, браузер. Аппаратным обеспечением называются все электронные и механические компоненты компьютера. Среди этих компонентов клавиатура, монитор, центральный процессор, видеокарта.

{caption: "Иллюстрация 1-4. Схема взаимодействия ОС с программами и аппаратным обеспечением", height: "50%"}
![Схема взаимодействия ОС](images/GeneralInformation/operating-system.png)

Рассмотрим схему. Приложения обращаются к аппаратным ресурсам не напрямую, а через [**системные библиотеки**](https://ru.wikipedia.org/wiki/Библиотека_(программирование)). Эти библиотеки являются частью ОС. Для работы с ними приложение должно следовать строгим правилам. 

[**Интерфейс прикладного программирования**](https://ru.wikipedia.org/wiki/API) определяет правила работы приложения с системными библиотеками. Он также известен как API (Application Programming Interface). 

Интерфейс — это набор соглашений о взаимодействии компонентов информационной системы. Такие соглашения со временем превращаются в стандарты. Например, POSIX стандарт описывает переносимый API для целого семейства ОС. Стандарты важны, поскольку гарантируют совместимость компонентов системы.

Помимо системных библиотек ОС включает в себя [**ядро**](https://ru.wikipedia.org/wiki/Ядро_операционной_системы) и [**драйвера устройств**](https://ru.wikipedia.org/wiki/Драйвер). Они определяют какие возможности аппаратуры доступны приложению. Драйвер — это специальная программа, которая предоставляет доступ к устройству. Когда приложение обращается к системной библиотеке, библиотека перенаправляет запрос в ядро ОС или драйвер. В некоторых случаях библиотека может выполнить запрос самостоятельно.

При обращении к системной библиотеке приложение вызывает одну из её [**функций**](https://ru.wikipedia.org/wiki/Функция_(программирование)). Функция — это фрагмент программы, который выполняет одну задачу. Представьте себе API как набор всех функций, доступных приложению. Кроме этого API определяет следующие аспекты взаимодействия приложения с ОС:

1. Какую операцию выполнит ОС при вызове конкретной системной функции?

2. Какие данные функция ожидает на вход?

3. Какие данные функция вернёт в качестве результата?

Следовать интерфейсу должна как ОС, так и приложение. Например, в документации к API сказано: "ОС создаёт файл при вызове функции X". Не зависимо от версии, ОС всегда должна следовать этому правилу. Оно гарантирует совместимость разных версий приложений и ОС. Такая совместимость невозможна без хорошо документированного и стандартизированного интерфейса.

Мы уже выяснили, что приложения могут работать без ОС. Однако, ОС предлагает готовые решения для работы с аппаратными ресурсами компьютера. Без этих решений разработчики приложений берут на себя работу с оборудованием. Такой подход требует много времени и сил. Представьте всё разнообразие комплектующих современных компьютеров. Приложение должно поддерживать все модели устройств (например, видеокарт). В противном случае оно не заработает у некоторых пользователей.

Рассмотрим возможности, которые предоставляет ОС через API интерфейс. Все электронные и механические компоненты компьютера можно рассматривать как ресурсы. Программы используют эти ресурсы для вычислений. Другими словами аппаратное обеспечение выполняет программы. API отражает возможности оборудования, которые доступны программе. Также интерфейс определяет порядок взаимодействия между несколькими программами и оборудованием.

Например, две программы не могут одновременно записывать данные на [жёсткий диск](https://ru.wikipedia.org/wiki/Жёсткий_диск#Технологии_записи_данных) в одну и ту же область. На это есть две причины:

1. Запись выполняется единственной магнитной головкой жёсткого диска. Она выполняет одну операцию за раз.

2. После записи данных первым приложением их может затереть второе приложение.

Чтобы избежать ошибок при записи, запросы к диску надо упорядочить. Обычно их помещают в очередь и исполняют друг за другом. За это отвечает ОС, а точнее её ядро (см. иллюстрацию 1-4).

В ядре реализован механизм для управления доступом к жёсткому диску. Этот механизм называется [**файловой системой**](https://ru.wikipedia.org/wiki/Файловая_система). Похожим образом ОС упорядочивает доступ ко всем [**периферийным**](https://ru.wikipedia.org/wiki/Периферийное_устройство) и внутренним устройствам компьютера. Этот доступ предоставляют драйвера устройств.

Что такое периферийные устройства, и чем они отличаются от внутренних? К периферийным относятся все устройства, отвечающие за ввод-вывод информации и её постоянное хранение. Вот несколько примеров:

* Клавиатура
* Мышь
* Микрофон
* Монитор
* Колонки
* Жёсткий диск

Внутренние устройства отвечают за обработку информации, то есть непосредственное исполнение программ. К ним относятся:

* [**Центральный процессор**](https://ru.wikipedia.org/wiki/Центральный_процессор) (central processing unit, CPU)
* [**Оперативная память**](https://ru.wikipedia.org/wiki/Оперативная_память) (random-access memory, RAM)
* [**Видеокарта**](https://ru.wikipedia.org/wiki/Видеокарта) (graphics processing unit, GPU)

Доступ к аппаратным ресурсам — это одна из возможностей ОС. Кроме аппаратных есть ещё и программные ресурсы самой ОС. Это повторяющийся код, ставший со временем служебными программами. Впоследствии его оформили в системные библиотеки (см. иллюстрацию 1-4). Некоторые из библиотек обслуживают устройства. Другие выполняют сложные алгоритмы для обработки данными.

Например, у Windows есть компонент под названием [**интерфейс графических устройств**](https://ru.wikipedia.org/wiki/GDI) (Graphical Device Interface или GDI). Он позволяет приложению манипулировать графическими объектами. Используя GDI, разработчики создают пользовательский интерфейс для своих программ.

Системные библиотеки с полезными алгоритмами (например, GDI) являются программными ресурсами ОС. Они уже установлены на вашем компьютере и готовы к использованию. Кроме них ОС предоставляет доступ к алгоритмам сторонних приложений и библиотек.

ОС не только управляет ресурсами. Она организует совместную работу нескольких приложений. Их запуск — уже нетривиальная задача. Её выполняет служебная программа ОС. После запуска приложения, ОС контролирует его выполнение. Если приложение нарушает какое-то ограничение, его принудительно завершают. Например, нарушением считается чтение недоступной памяти. В следующем разделе мы подробно рассмотрим запуск и исполнение программы.

Если ОС многопользовательская, она контролирует доступ к данным. Благодаря этому, каждый пользователь может работать только со следующими объектами файловой системы:

* Файлы и каталоги, принадлежащие пользователю.
* Файлы и каталоги, к которым кто-то предоставил доступ.

Подведём итог. Современная ОС выполняет следующие функции:

1. Предоставляет и упорядочивает доступ к аппаратным ресурсам компьютера.

2. Предоставляет собственные программные ресурсы в виде системных библиотек.

3. Запускает приложения.

4. Организует взаимодействие приложений друг с другом.

5. Контролирует доступ пользователей к данным.

Посмотрите внимательно на перечисленные функции ОС. Наверное, вы догадались, что без ОС нельзя запустить несколько приложений одновременно. Проблема в том, что их разработчики не знают, в каком сочетании программы будут выполняться. Только ОС имеет достаточно информации, чтобы эффективно распределить ресурсы компьютера.

### Современные ОС

Мы познакомились с основными возможностями ОС. Теперь рассмотрим современные ОС. Выберите любую из них, и вы получите примерно одни и те же функции. Основные отличия заключаются в способах реализации этих функций. Такие особенности реализации и решения, которые к ним привели, называются [**архитектурой**](https://ru.wikipedia.org/wiki/Архитектура_программного_обеспечения).

У современных ОС есть две особенности. Они определяют поведение системы и способ её взаимодействия с пользователем. Речь идёт о многозадачности и графическом интерфейсе. Рассмотрим их подробнее.

#### Многозадачность

Большинство современных ОС [**многозадачны**](https://ru.wikipedia.org/wiki/Многозадачность). Это означает, что они исполняют несколько программ одновременно. Системы с этим свойством вытеснили ОС без него. Почему это свойство оказалось таким важным?

В 1960-е годы возникла проблема эффективного использования компьютеров. В то время они представляли собой шкафы с электроникой и стоили дорого. Компьютер такого типа называется [**мейнфреймом**](https://ru.wikipedia.org/wiki/Мейнфрейм). Только крупные компании и университеты могли позволить себе такое оборудование. Из-за высокой цены любой простой компьютера был неприемлем.

Первые операционные системы исполняли программы друг за другом без задержек. В таких ОС программы и их входные данные подготавливались заранее. Они записывались на устройство хранения (например, магнитную ленту). Эта лента подавалась на устройство ввода. Компьютер последовательно исполнял программы и выводил их результаты на устройство вывода (например, принтер). Такой режим работы называется [**пакетная обработка**](https://ru.wikipedia.org/wiki/Пакетное_задание) (batch processing). Его главное преимущество — экономия времени на переключение между задачами.

Пакетная обработка позволила эффективно использовать мейнфреймы в 1960-е годы. Она автоматизировала загрузку программ. Оператор стал не нужен для этой работы. Однако, у системы оставалось [**узкое место**](https://ru.wikipedia.org/wiki/Узкое_место). Вычислительная мощность процессоров значительно возрастала ежегодно. Скорость работы периферийных устройств почти не менялась. Из-за этого процессор быстро выполнял вычисления и дальше ждал ввода-вывода данных. Таким образом компьютер работал не на полную мощность.

I> Узкое место (bottleneck) — компонент или ресурс информационной системы, который ограничивает её общую производительность или пропускную способность.

Почему процессору приходится ждать периферийные устройства? Рассмотрим пример. Представьте, что мейнфрейм последовательно выполняет программы. Он считывает данные с магнитной ленты и печатает результаты на принтере. ОС загружает программу и исполняет её инструкции. Затем загружается следующая программа и так далее.

Проблема возникает на этапах чтения данных и печати результата. Время доступа к данным на магнитной ленте огромно в масштабах центрального процессора. Между двумя операциями чтения, он успел бы выполнить ряд вычислений. Но он этого не делает. Причина в том, что все ресурсы компьютера использует только одна программа. Она загружена в память в данный момент. То же происходит при выводе результатов на печать. Принтер — это электромеханическое устройство. Поэтому он работает очень медленно.

Проблема простоя центрального процессора привела к идее [**мультипрограммирования**](https://ru.wikipedia.org/wiki/Мультипрограммирование). Суть идеи в одновременной загрузке нескольких программ в память компьютера. Первая из них выполняется до тех пор, пока доступны все необходимые ей ресурсы. Как только один из ресурсов оказывается занят, выполнение программы останавливается. Тогда ОС переключается на следующую программу.

Рассмотрим пример переключения программ. Предположим, что приложение читает данные с жёсткого диска. Пока контроллер диска читает первую часть данных, он занят и не может обработать запрос на чтение следующей части. Поэтому приложение ожидает, когда освободится контроллер. ОС останавливает работу приложения и переключается на другую программу. Она исполняется до конца или до момента, когда нужный ей ресурс окажется занят. После этого ОС опять переключается на другую программу.

Мультипрограммирование стало прототипом многозадачности, которую используют современные ОС. Мультипрограммирование хорошо справляется с режимом пакетной обработки. Однако, этот принцип распределения нагрузки не подходит для систем с [**интерактивным взаимодействием**](https://ru.wikipedia.org/wiki/Интерактивность). В таких системах действия пользователя являются событиями. Например, нажатие клавиши. ОС должна обработать каждое событие сразу. Если не выполнить это требование, пользователь не сможет работать с системой.

Рассмотрим пример работы с интерактивной системой. Представьте, что вы набираете текст в редакторе MS Office. Вы нажимаете клавишу и ожидаете, что соответствующий символ отобразится на экране. Если задержка между нажатием и отображением увеличится до нескольких секунда, вы не сможете эффективно работать. Большую часть времени вы будете ожидать отображение символа, а не набирать текст. Печатать вслепую не получится из-за возможных ошибок.

Мультипрограммирование не справляется с обработкой событий в интерактивных системах. Причина в том, что момент переключения задач непредсказуем. Переключение происходит при завершении программы или её обращении к занятому ресурсу. Представьте, что редактор MS Office не активен в данный момент. Тогда вы не можете предсказать, когда он обработает нажатие клавиши. Это может случиться через секунду или несколько минут. Такое поведение неприемлемо для интерфейса пользователя.

Многозадачность решает проблему быстрого отклика в интерактивных системах. Способ её реализации постепенно развивался и усложнялся. В современных ОС применяется [**вытесняющая многозадачность**](https://ru.wikipedia.org/wiki/Вытесняющая_многозадачность) с псевдопараллельной обработкой задач. Это означает, что ОС самостоятельно выбирает программу для выполнения. При выборе учитываются приоритеты всех запущенных приложений. Более приоритетные приложения получают аппаратные ресурсы чаще, чем низкоприоритетные. Механизм переключения задач реализован в ядре ОС. Он называется [**планировщиком задач**](https://ru.wikipedia.org/wiki/Диспетчер_операционной_системы).

Псевдопараллельность означает, что в каждый момент времени выполняется только одна задача. При этом ОС переключается между задачами так быстро, что пользователь этого не замечает. Ему кажется, что компьютер выполняет одновременно несколько программ. Но на самом деле, каждая программа и компонент ОС получают аппаратные ресурсы в строго определённые моменты времени. Такой подход позволяет ОС немедленно реагировать на любое действие пользователя. 

Одновременное выполнение программ возможно только на компьютерах с несколькими процессорами или с [многоядерными](https://ru.wikipedia.org/wiki/Ядро_микропроцессора) процессорами. На таких компьютерах число одновременно работающих программ примерно равно числу ядер всех процессоров. При этом также применяется механизм вытесняющей многозадачности с постоянным переключением задач. Он универсален и балансирует нагрузку на любых системах, независимо от числа ядер. Так выдерживается приемлемое время отклика на действия пользователя.

#### Интерфейс пользователя

Современные ОС решают широкий круг задач. В зависимости от задачи выбирается компьютер и ОС к нему. Вот основные типы современных компьютеров:

* [Персональные компьютеры](https://ru.wikipedia.org/wiki/Персональный_компьютер) (ПК) и ноутбуки.
* Мобильные телефоны и планшеты.
* Сервера.
* [Встраиваемые системы](https://ru.wikipedia.org/wiki/Встраиваемая_система).

Мы рассмотрим ОС только для ПК и ноутбуков. Помимо механизма многозадачности они предоставляют [**графический интерфейс пользователя**](https://ru.wikipedia.org/wiki/Графический_интерфейс_пользователя) (graphical user interface или GUI). Здесь термин интерфейс означает способ взаимодействия человека с системой. Так пользователь запускает приложения, настраивает устройства компьютера и компоненты ОС. Рассмотрим подробнее историю возникновения графического интерфейса.

До 1960 года коммерческие компьютеры не имели интерактивного режима работы. Его впервые реализовала компания [Digital Equipment Corporation](https://ru.wikipedia.org/wiki/Digital_Equipment_Corporation) для своего нового [мини-компьютера](https://ru.wikipedia.org/wiki/Мини-компьютер) [PDP-1](https://ru.wikipedia.org/wiki/PDP-1) в 1959 году. Это был принципиально новый подход к работе с компьютером.

До появления PDP-1 на рынке доминировали мейнфреймы от IBM. Это продолжалось все 1950-е годы. Мейнфреймы работали в режиме пакетной обработки и хорошо справлялись с вычислительными задачами. Их операционные системы с поддержкой мультипрограммирования автоматизировали загрузку программ и обеспечивали высокую производительность. Но этих возможностей не хватало для новых задач с которыми столкнулись компьютерные инженеры.

Идея интерактивной работы с компьютером появилась при разработке военного проекта SAGE. Он выполнялся по заказу ВВС США. ВВС была нужна автоматизированная система ПВО для обнаружения советских бомбардировщиков.

Инженеры проекта SAGE столкнулись с проблемой. Оператор системы должен был получать данные с радаров в реальном времени. Если он замечал угрозу, он отдавал команду на перехват бомбардировщиков. Однако, существующие тогда методы работы с компьютером не подходили для этой задачи. Они не позволяли выводить информацию в реальном времени и обрабатывать ввод пользователя в любой момент.

Тогда инженеры SAGE предложили идею нового способа работы с компьютером. Его назвали интерактивный режим. Этот режим использовал компьютер [AN/FSQ-7](https://en.wikipedia.org/wiki/AN/FSQ-7_Combat_Direction_Central) (см иллюстрацию 1-5). Его разработали в рамках проекта для управления системой ПВО. Данные с радаров выводились на [**электронно-лучевой монитор**](https://ru.wikipedia.org/wiki/Кинескоп). Оператор давал команды с помощью [**светового пера**](https://ru.wikipedia.org/wiki/Световое_перо).

{caption: "Иллюстрация 1-5. Компьютер AN/FSQ-7"}
![Компьютер AN/FSQ-7](images/GeneralInformation/AN-FSQ-7.jpg)

Метод интерактивной работы с компьютером стал известен и популярен в научных кругах. Пакетная обработка успешно справлялась с выполнением программ. Но в этом режиме их разработка и отладка была неудобной.

Вот как выглядела разработка программы для мейнфрейма. Программист составлял алгоритм и записывал его на устройство хранения. Это устройство он передавал оператору компьютера. Оператор добавлял задачу на выполнение программы  в очередь. Ожидание в очереди занимало часы. Если программа исполнялась с ошибкой, программист её исправлял и снова ожидал свой очереди на исполнение. В результате тестирование даже небольшой программы занимало дни.

Интерактивный режим полностью изменил процесс разработки программ. Теперь программист мог запустить программу и сразу получить её результат. Такой процесс на порядок ускорил разработку и отладку приложений. За несколько часов выполнялась работа, требовавшая раньше нескольких дней.

Интерактивный режим работы повысил требования к ОС. Теперь она должна сразу реагировать на действия пользователя. Новый механизм многозадачности решил эту проблему.

Интерактивный режим поддерживают не только многозадачные ОС, но и однозадачные. Пример такой системы — [MS-DOS](https://ru.wikipedia.org/wiki/MS-DOS). Её разработала компания Microsoft для относительно дешёвых персональных компьютеров 1980-х годов.

Интерактивный и однозадачный режимы можно совместить. Однако, такое решение не применялось для мейнфреймов 1960-х годов. Причина в том, что выделять все ресурсы мейнфрейма для одной программы было слишком дорого. Вместо этого применялся режим [**разделение времени**](https://ru.wikipedia.org/wiki/Разделение_времени) (time-sharing). Он позволял нескольким пользователям работать с компьютером одновременно.

Когда в 1980-х появились первые персональные компьютеры, на них устанавливались однозадачные ОС. Эти компьютеры уступали по производительности мейнфреймам. Их аппаратных ресурсов не хватало для запуска многозадачных ОС того времени. Однозадачные ОС были проще и не так требовательны к производительности. Несмотря на свою простоту, они поддерживали интерактивную работу. Этот режим стал особенно привлекательным для пользователей ПК.

Для интерактивного режима понадобился новый способ балансировки нагрузки системы. Кроме этого надо было заменить существующие устройства ввода-вывода: магнитные ленты и принтеры. Их использовали на протяжении 1950-х и в начале 1960-х годов. Для нового интерактивного режима они не подходили.

[**Телетайп**](https://ru.wikipedia.org/wiki/Телетайп) (teletype) стал прототипом устройства для интерактивной работы с компьютером. Иллюстрация 1-6 демонстрирует телетайп Model 33. Он представляет собой электромеханическую печатную машинку. С помощью проводов она подключается к такой же машинке. После соединения двух телетайпов их операторы могут передавать друг другу текстовые сообщения. Отправитель набирает текст на своём устройстве. Нажатия клавиш передаются на устройство получателя. Оно печатает каждую принятую букву на бумаге.

{caption: "Иллюстрация 1-6. Телетайп Model 33", height: "50%"}
![Телетайп Model 33](images/GeneralInformation/teletype.jpg)

Телетайп стали подключать к мейнфреймам. На его клавиатуре пользователь набирал команды. Мейнфрейм их получал, исполнял и отправлял результат обратно. Этот результат печатался на бумаге. Такой способ взаимодействия с компьютером стал известен как [**интерфейс командной строки**](https://ru.wikipedia.org/wiki/Интерфейс_командной_строки) (command-line interface или CLI).

В качестве устройства вывода телетайп использует принтер. Он работает медленно. Вывод одной строки занимает около 10 секунд. Со временем принтер заменили на монитор. Это ускорило вывод данных в несколько раз. Новое устройство с клавиатурой и монитором получило название [**терминал**](https://ru.wikipedia.org/wiki/Компьютерный_терминал). Он вытеснил телетайпы в 1970-х годах.

Иллюстрация 1-7 демонстрирует современный интерфейс командной строки. Перед вами окно [**эмулятора терминала**](https://ru.wikipedia.org/wiki/Эмулятор_терминала). Это приложение имитирует настоящий терминал. Он нужен для работы некоторых программ. Благодаря эмулятору решается задача совместимости этих программ и современной ОС.

Эмулятор терминала на иллюстрации 1-7 называется [Terminator](https://en.wikipedia.org/wiki/Terminator_(terminal_emulator)). В нём запущен интерпретатор командной строки Bash. Интерпретатор выполнил программы ping и ls. Вы видите их результаты в окне терминала.

{caption: "Иллюстрация 1-7. Интерфейс командной строки", height: "50%"}
![Интерфейс командной строки](images/GeneralInformation/cli.png)

Интерфейс командной строки появился в середине 1960-х. Однако, он востребован и сегодня. У него есть ряд преимуществ по сравнению с графическим интерфейсом. Одно из них — низкие требования к вычислительным ресурсам. CLI надёжно работает и на низкопроизводительных встраиваемых компьютерах, и на мощных серверах. Если использовать CLI для удалённого доступа к компьютеру, скорость соединения может быть низкой. Сервер всё равно получит команды пользователя.

У интерфейса командной строки есть и недостатки. Главная его проблема в сложности освоения. Пользователю доступны сотни команд. У каждой из них есть несколько входных параметров. Эти параметры задают разные режимы работы. Чтобы запомнить хотя бы основные команды и их режимы, нужно время и практика.

Проблему наглядного представления доступных команд решает [**текстовый интерфейс пользователя**](https://ru.wikipedia.org/wiki/Текстовый_интерфейс_пользователя) (textual user interface или TUI). В нём наряду с буквенными и цифровыми символами используется [**псевдографика**](https://ru.wikipedia.org/wiki/Псевдографика). Псевдографикой называются специальные символы для изображения графических примитивов. Примитивы — это линии, прямоугольники, треугольники и т.д.

Иллюстрация 1-8 демонстрирует пример текстового интерфейса. Это вывод статистики использования системных ресурсов программой htop.

{caption: "Иллюстрация 1-8. Текстовый интерфейс пользователя", height: "50%"}
![Текстовый интерфейс пользователя](images/GeneralInformation/tui.png)

В 1980-е производительность ПК стремительно росла. Это позволило заменить псевдографику на реальные графические элементы. Примеры таких элементов: окна, иконки, кнопки и т.д. В результате появился полноценный графический интерфейс. Он применяется в современных ОС.

Первый графический интерфейс предназначался для мини-компьютера [Xerox Alto](https://ru.wikipedia.org/wiki/Xerox_Alto) (см. иллюстрацию 1-10). Его разработали в 1973 году в исследовательском центре [Xerox PARC](https://ru.wikipedia.org/wiki/Xerox_PARC). Однако, интерфейс не получил широкого распространения до 1980-х годов. Он требовал много памяти и высокой производительности компьютера. В то время ПК с такими характеристиками стоили слишком дорого для рядовых пользователей.

Первый недорогой ПК с графическим интерфейсом выпустила компания Apple в 1983 году. Он назывался Lisa.

{caption: "Иллюстрация 1-10. Мини-компьютер Xerox Alto", height: "50%"}
![Мини-компьютер Xerox Alto](images/GeneralInformation/xerox-alto.jpg)

Иллюстрация 1-9 демонстрирует графический интерфейс ОС Windows. Это скриншот рабочего стола. На нём открыты окна трёх приложений: Проводник, Блокнот и Калькулятор. Они работают одновременно.

{caption: "Иллюстрация 1-9. Графический интерфейс пользователя"}
![Графический интерфейс пользователя](images/GeneralInformation/gui.png)

#### Семейства ОС

Сегодня на рынке персональных компьютеров доминируют три семейства ОС:

* [Windows](https://ru.wikipedia.org/wiki/Windows)
* [Linux](https://ru.wikipedia.org/wiki/Linux)
* [macOS](https://ru.wikipedia.org/wiki/MacOS)

Термин "семейство" означает ряд версий ОС, которые следуют одним и тем же архитектурным решениям. Кроме того большинство функций в этих ОС реализованы одинаково.

Разработчики ОС склонны придерживаться одной и той же архитектуры. Они не предлагают что-то принципиально новое в следующих версиях своего продукта. Почему?

На самом деле изменения в современных ОС происходят, но постепенно и медленно. Причина этого в [**обратной совместимости**](https://ru.wikipedia.org/wiki/Обратная_совместимость). Такая совместимость означает, что новые версии ОС повторяют функции старых версий. Эти функции нужны для работы существующих программ. На первый взгляд это требование кажется необязательным. Однако, это серьёзное ограничение для разработки программного обеспечения. Давайте разберёмся, почему это так.

Представьте, что вы написали программу для Windows и продаёте её. Иногда пользователи обнаруживают в программе ошибки. Вы их исправляете. Время от времени вы добавляете новые функции.

Теперь представьте, что вышла новая версия Windows. В ней компания Microsoft полностью изменила архитектуру ОС. Поэтому ваша программа на ней не работает. У пользователей программы есть два решения: 

* Перейти на новую версию Windows и ждать исправления вашей программы.

* Отказаться от обновления Windows.

Если ваша программа нужна пользователям для ежедневной работы, они откажутся от обновления Windows. Для них будет разумнее подождать, пока вы исправите программу для работы с новой версией ОС. Тогда они смогут обновить и программу, и ОС без ущерба для своей работы.

Предположим, что новая Windows принципиально отличается от предыдущей. Это значит, что вам придётся полностью переписать программу. Подсчитайте всё время, которое вы уже потратили на исправление ошибок и добавление новых функций. Эту работу придётся повторить в полном объёме. Скорее всего, вы откажетесь от этой идеи и предложите пользователям оставаться на старой версии Windows.

Windows самая популярная ОС для ПК и ноутбуков. Поэтому для неё написано много программ, подобных вашей. Их разработчики придут к тому же решению, что и вы. В результате новая версия Windows окажется никому не нужна. В этом суть проблемы обратной совместимости. Из-за неё разработчики ОС относятся к изменениям с осторожностью. Лучшее решение для них — разработать и поддерживать семейство похожих ОС.

Приложения оказывают огромное влияние на развитие и распространение ОС. Например, ОС Windows и персональные компьютеры от IBM обязаны своим успехом табличному процессору [Lotus 1-2-3](https://ru.wikipedia.org/wiki/Lotus_1-2-3). Он запускался только на ОС Windows, которая работала только на ПК от IBM. Ради Lotus 1-2-3 пользователи покупали и компьютер, и ОС. Комбинация аппаратуры и программного обеспечения называется [**компьютерной платформой**](https://ru.wikipedia.org/wiki/Компьютерная_платформа). Популярное приложение, которое выводит платформу на широкий рынок, получило название [**killer application**](https://ru.wikipedia.org/wiki/Killer_application) (букв. убойное приложение).

Табличный процессор [VisiCalc](https://ru.wikipedia.org/wiki/VisiCalc) — ещё один пример убойного приложения. Он содействовал распространению компьютеров [Apple II](https://ru.wikipedia.org/wiki/Apple_II). Точно так же бесплатные компиляторы языков C, Fortran и Pascal подогрели интерес к Unix в университетских кругах.

За каждой из трёх доминирующих сегодня ОС стоит убойное приложение. Они дали начальный рывок в конкуренции за новыми пользователями. Далее срабатывал [сетевой эффект](https://ru.wikipedia.org/wiki/Сетевой_эффект). Его суть в том, что разработчики новых приложений выбирали самую распространённую платформу.

Чем отличаются семейства ОС между собой? Windows и Linux примечательны тем, что не привязаны к конкретной аппаратной платформе. Это значит, что они устанавливаются на любой персональный компьютер или ноутбук. В отличие от них macOS запускается только на компьютерах Apple. Чтобы установить macOS на другую аппаратную платформу, понадобится неофициальная [модифицированная версия](https://ru.wikipedia.org/wiki/OSx86) ОС.

Совместимость с аппаратной платформой — это пример архитектурного решения. Таких решений много. Все вместе они определяют особенности каждого семейства.

Предположим, что вы выбираете ОС для своего нового приложения. Кроме популярности системы и её архитектуры, вам следует учесть её инфраструктуру для разработки. Инфраструктурой называются доступные инструменты. К ним относится IDE, компилятор, система сборки, система контроля версий.

Инфраструктура и архитектура ОС навязывают разработчикам приложений определённые решения. Эти решения называются **культурой разработки** под конкретную ОС. Обратите внимание на важный момент: под разные ОС программы следует разрабатывать по-разному. Постарайтесь это учитывать.

Рассмотрим различие культур разработки программ на примере Windows и Linux.

#### Windows

Windows — это [проприетарная](https://ru.wikipedia.org/wiki/Проприетарное_программное_обеспечение) ОС. Исходный код проприетарных программ закрыт. Вы не можете его прочитать и изменить без специальных средств. Другими словами нет законного способа узнать про такое ПО больше, чем рассказывает его документация.

Чтобы установить Windows на компьютер, вы должны купить её у компании Microsoft. Есть и другой способ. Производители компьютеров часто сами устанавливают Windows на свои устройства. В этом случае цена на ОС входит в конечную стоимость компьютера.

Целевой платформой Windows были и остаются относительно дешёвые ПК и ноутбуки. Многие могут позволить себе купить такое устройство. Поэтому рынок потенциальных пользователей Windows огромен. Microsoft стремится сохранить конкурентное преимущество на этом рынке. Компания опасается появления аналогов Windows с такими же возможностями. Чтобы это предотвратить, Microsoft защищает свою интеллектуальную собственность не только техническими, но и юридическими путями. Например, пользовательское соглашение запрещает вам исследовать внутреннее устройство ОС.

Первая версия Windows была разработана в 1985 году. С тех пор семейство этих ОС развивается более 30 лет. Благодаря его популярности многие разработчики выбирают Windows в качестве платформы для своих программ. Однако, первые приложения разработала сама компания Microsoft. Например, это офисный пакет [Microsoft Office](https://ru.wikipedia.org/wiki/Microsoft_Office) и [стандартные приложения Windows](https://ru.wikipedia.org/wiki/Категория:Стандартные_приложения_Windows). Они задали некий стандарт и стали образцом для подражания.

Microsoft придерживалась того же принципа при разработке приложений, что и для ОС. Это принцип закрытости: 

* Исходный код недоступен для пользователей
* Форматы данных недокументированны
* Сторонние утилиты не имеют доступа к возможностям ПО.

Эти решения хорошо защищают интеллектуальную собственность Microsoft.

Разработчики программ последовали примеру Microsoft. Они придерживались той же философии закрытости. В результате их приложения получались самодостаточными и независимы друг от друга. Форматы их данных закодированы и недокументированны.

Если вы опытный пользователь компьютера, то сразу узнаете типичное Windows-приложение. Это окно с [элементами интерфейса](https://ru.wikipedia.org/wiki/Элемент_интерфейса) вроде кнопок, полей ввода, вкладок и т.д. С их помощью пользователь манипулирует некоторыми данными. Например, это может быть текст, изображение или звуковая запись. Результат работы сохраняется на жёсткий диск. Его можно открыть снова в этом же приложении. Если вы напишете собственную Windows-программу, она будет выглядеть и работать похожим образом. Такая преемственность решений и называется культурой разработки под ОС.

#### Linux

Linux заимствовал идеи и решения ОС [Unix](https://ru.wikipedia.org/wiki/Unix). Обе системы следуют набору стандартов [POSIX](https://ru.wikipedia.org/wiki/POSIX) (Portable Operating System Interface). POSIX определяет интерфейсы взаимодействия прикладных программ с ОС. Linux и Unix получились похожи из-за следования одному стандарту. Обратимся к истокам Unix, чтобы лучше понять его архитектурные решения.

ОС Unix разработали два инженера из компании Bell Labs в конце 1960-х годов. Это был хобби-проект [Кена Томпсона](https://ru.wikipedia.org/wiki/Томпсон,_Кен) и [Денниса Ритчи](https://ru.wikipedia.org/wiki/Ритчи,_Деннис). В Bell Labs они работали над проектом [**Multics**](https://ru.wikipedia.org/wiki/Multics).

ОС Multics была совместной разработкой Массачусетского технологического института (MIT), компании General Electric (GE) и Bell Labs. Она предназначалась для нового мейнфрейма GE-645 компании General Electric. Иллюстрация 1-11 демонстрирует этот компьютер.

{caption: "Иллюстрация 1-11. Мейнфрейм модели GE-645", height: "30%"}
![Мейнфрейм модели GE-645](images/GeneralInformation/ge-645.jpg)

В Multics разработчики применили ряд инновационных решений. Одним из них было разделение времени. Так мейнфрейм GE-645 стал первым компьютером, на котором могли одновременно работать несколько пользователей. Для разделения аппаратных ресурсов между ними применялась многозадачность.

ОС Multics оказалась слишком сложной из-за многочисленных инноваций и высоких требований. На её разработку потребовалось больше времени и денег, чем планировалось изначально. Из-за этого компания Bell Labs вышла из проекта в 1969 году.

Проект Multics был интересен с технической стороны. Поэтому многие инженеры Bell Labs продолжили работу над ним самостоятельно. Одним из них был Кен Томпсон. Он решил создать собственную ОС для компьютера GE-645. Томпсон начал писать ядро системы и продублировал некоторые механизмы Multics. Однако, скоро General Electric потребовала вернуть свой компьютер GE-645. Bell Labs получила его во временное пользование для работы на Multics. В результате Кен Томпсон остался без аппаратной платформы для разработки. Из-за этого он не смог больше развивать свой проект.

Параллельно с работой над аналогом Multics Томпсон писал компьютерную игру [Space Travel](https://ru.wikipedia.org/wiki/Space_Travel) как хобби. Она запускалась на мейнфрейме General Electric прошлого поколения GE-635. Этот компьютер работал под управлением ОС [GECOS](https://ru.wikipedia.org/wiki/GCOS). GE-635 представлял собой шкафы с электроникой стоимостью около 7500000$. Его активно использовали инженеры Bell Labs и Томпсону редко удавалось с ним работать.

Ограниченный доступ к компьютеру GE-635 стал проблемой. Для её решения Томпсон перенёс свою игру на относительно недорогой мини-компьютер [PDP-7](https://ru.wikipedia.org/wiki/PDP-7) (см. иллюстрацию 1-12). Он стоил около 72000$. Сотрудники Bell Labs использовали его редко и большую часть рабочего времени он был доступен. При переносе Space Travel на другую платформу возникла одна проблема. Игра использовала возможности GECOS, но ОС компьютера PDP-7 их не предоставляла.

В этот момент к Томпсону присоединился его коллега Деннис Ритчи. Вмести они реализовали необходимые для игры возможности GECOS на PDP-7. Это был набор библиотек и подсистем. Со временем они развились в самостоятельную ОС, получившую название Unix. В ней разработчики применили некоторые инновационные идеи Multics.

{caption: "Иллюстрация 1-12. Мини-компьютер PDP-7", height: "30%"}
![Мини-компьютер PDP-7](images/GeneralInformation/pdp-7.jpg)

Томпсон и Ритчи не собирались продавать свои разработки. Поэтому вопрос о защите интеллектуальной собственности даже не обсуждался. Они разрабатывали Unix для собственных нужд. Когда система заработала, её распространяли с открытым исходным кодом. Все сотрудники Bell Labs могли скопировать и использовать Unix в своих проектах. Это вполне естественное решение для передачи полезной системы коллегам.

ОС Unix стала популярна среди инженеров Bell Labs. Томпсон и Ритчи представили её на конференции по операционным системам под названием "Symposium on Operating Systems Principles" в 1973 году. ОС понравилась участникам конференции и многие захотели её приобрести. Проблема была в том, что Bell Labs принадлежала компании AT&T. Поэтому сотрудники Bell Labs не имели права распространять программное обеспечение.

В компании AT&T заметили успех Unix. Руководство решило продавать ОС вместе с исходным кодом высшим учебным заведениям США. Сумма лицензии составляла $20000. Эта цена была слишком высокой для коммерческих пользователей, но подъёмной для университетов. Так ОС Unix распространилась среди учебных заведений и продолжала развиваться там.

[Линус Торвальдс](https://ru.wikipedia.org/wiki/Торвальдс,_Линус) познакомился с Unix во время учёбы в Хельсинкском университете. Unix произвела на него впечатление и привела к идее создать собственную ОС. Впоследствии она получила название Linux. Эта работа не была хобби для развлечения. Торвальдс решал практическую задачу. Ему нужна была Unix-совместимая ОС, чтобы выполнять университетские задания дома на ПК. В то время подходящей ему ОС не существовало.

В Хельсинкском университете студенты работали на мини-компьютере MicroVAX под управлением Unix. У многих из них был дома персональный компьютер. Но Unix на ПК не запускалась. Единственной альтернативой Unix для домашнего использования была [Minix](https://ru.wikipedia.org/wiki/Minix).

Эндрю Таненбаум разработал Minix в 1987 году для ПК от IBM с процессором Intel 80268. Minix создавалась исключительно для учебных целей. Поэтому Эндрю отказывался вносить в неё изменения для поддержки более современных компьютеров. Эти изменения сделали бы систему сложнее. Тогда она стала бы не пригодна для обучения студентов.

Торвальдс задался целью написать Unix-совместимую ОС для своего нового компьютера IBM с процессором Intel 80386. Для разработки он использовал Minix. Однако, никакие её части не вошли в состав новой ОС.

Торвальдс разработал ОС для собственных нужд. У него не было коммерческих интересов, как и у создателей Unix. Вместо этого Торвальдс свободно поделился ею со всеми желающими. Это привело к тому, что Linux стала бесплатной. Она свободно распространялась с исходным кодом через интернет. Доступность и отсутствие Unix-совместимых альтернатив для новых ПК от IBM сделало ОС популярной.

Торвальдс разработал только ядро ОС. Оно предоставляло функции управления памятью, файловую систему, драйвера устройств и планировщик задач. Для полноценной ОС не хватало интерфейса, через который пользователи получили бы доступ к этим возможностям. Поэтому Linux не был готов к использованию в своём исходном виде.

Решение проблемы пришло из [проекта GNU](https://ru.wikipedia.org/wiki/Проект_GNU). [Ричард Столлман](https://ru.wikipedia.org/wiki/Столлман,_Ричард_Мэттью) начал работу над ним в Массачусетском технологическом институте (MIT) в 1983 году. Он поставил себе задачу разработать основное программное обеспечение для компьютера и сделать его бесплатным. Главные программы проекта GNU следующие:

* GCC компилятор
* Системная библиотека glibc
* Системные утилиты
* Оболочка Bash.

Торвальдс включил эти программы в свой проект и выпустил первый [дистрибутив](https://ru.wikipedia.org/wiki/Дистрибутив_Linux) Linux в 1991 году.

У первых версий Linux не было графического интерфейса. Пользователь запускал все приложения из командной строки. Только некоторые сложные приложения имели текстовый интерфейс. GUI появился в Linux в середине 1990-х годов. Он использовал бесплатную оконную систему [X Window System](https://ru.wikipedia.org/wiki/X_Window_System). X Window позволила разработчикам писать приложения с графическим интерфейсом.

Unix и Linux развивались в особых условиях. Они отличались от обычного жизненного цикла проприетарных систем. Эти условия породили особую культуру разработки. Обе системы дорабатывались в университетских кругах. Преподаватели и студенты ИТ специальностей использовали эти ОС в своей ежедневной работе. Они хорошо разбирались в работе программного обеспечения и охотно вносили исправления в обе системы.

Разберёмся, что отличает культуру разработки под Unix. Пользователи этой ОС предпочитают использовать узкоспециализированные утилиты командной строки. Так для каждой прикладной задачи есть своя утилита. Она хорошо написана, многократно протестирована и работает максимально эффективно. При этом все возможности утилиты нацелены на решение одной задачи. Это не универсальная программа, которая подходит для нескольких целей.

Предположим, что вы решаете сложную задачу. Одна узкоспециализированная утилита не в состоянии с ней справится. Но если скомбинировать несколько утилит, задача решается быстро и эффективно. Такое взаимодействие программ стало возможным благодаря простому формату данных. Большинство Unix утилит работают с [текстовыми](https://ru.wikipedia.org/wiki/Текстовые_данные) данными. Такой формат очевиден и не нуждается в документации.

Культура разработки Linux во многом повторяет традиции Unix. Она отличается от стандартов, принятых в Windows.

В Windows каждое приложение монолитно и самостоятельно выполняет все свои задачи. Оно не полагается на сторонние утилиты. Причина в том, что большинство Windows-программ платные и могут быть недоступны для пользователя. Поэтому каждый разработчик полагается только на себя. Для работы своего приложения он не в праве требовать от пользователя купить что-то дополнительное.

В Linux программы зависят друг от друга. Большинство утилит бесплатны, взаимозаменяемы и легко доступны через интернет. Поэтому вполне естественно, что одно приложение требует загрузить и установить недостающий ему системный компонент или другое приложение.

Взаимодействие программ принципиально важно в Linux. Даже монолитные графические Linux-приложения обычно предоставляют дополнительный интерфейс командной строки. Таким образом они органично вписываются в экосистему ОС. Используя командный интерфейс, вы можете интегрировать их с другими утилитами и приложениями.

В Linux решение сложной задачи часто строится на сочетании узкоспециализированных программ. Таким образом алгоритм вычисления собирается по частям. Для этого в Linux и Unix есть специальный инструмент — [командная оболочка](https://ru.wikipedia.org/wiki/Командная_оболочка_Unix). Она позволяет пользователю исполнять команды и сохранять их в скрипты. Первая версия командной оболочки [Bourne shell](https://ru.wikipedia.org/wiki/Bourne_shell) для Unix появилась в 1979 году. Сегодня она считается устаревшей. В современных Linux дистрибутивах её вытеснил [Bash](https://ru.wikipedia.org/wiki/Bash). В этой книге мы с ним познакомимся.

Мы кратко рассмотрели культуры разработки Windows и Linux. Нельзя отдать однозначное предпочтение одной из них. Их сравнение давно служит поводом для бесконечных споров. Каждая из культур имеет свои достоинства и недостатки. Например, типичные для Windows монолитные приложения лучше справляются с задачами, требующими интенсивных расчётов. При комбинации узкоспециализированных Linux-утилит в этом случае появляются накладные расходы. Они связаны с запуском утилит и передачей данных между ними. Всё это требует дополнительного времени. В результате задача выполняется дольше.

Сегодня мы наблюдаем синтез культур Windows и Linux. Компания Microsoft начала активно принимать участие в разработке открытого ПО. Среди таких проектов ядро Linux, сетевой протокол [Samba](https://ru.wikipedia.org/wiki/Samba), библиотека для машинного обучения [PyTorch](https://ru.wikipedia.org/wiki/PyTorch), браузер [Chromium](https://ru.wikipedia.org/wiki/Chromium) и т.д. Microsoft также выложила в открытый доступ некоторые из своих проектов: программную платформу [.NET](https://ru.wikipedia.org/wiki/.NET_Framework), оболочку PowerShell, среду разработки VS Code и др.

С другой стороны всё больше коммерческих приложений переносятся на Linux: браузеры, инструменты для разработки программ, игры, мессенджеры и т.д. При этом их разработчики часто не готовы вносить изменения, продиктованные Linux-культурой. Такие изменения требуют времени и сил. Кроме того, они усложняют сопровождение продукта. Вместо одного приложения получается два: под каждую платформу разная версия. Поэтому разработчики переносят свои приложения с минимальными изменениями. В результате под Linux всё чаще встречаются приложения, выполненные в типичном Windows-стиле.

О плюсах и минусах синтеза культур можно спорить. Но очевидно одно: чем больше приложений запускается на ОС, тем популярнее она становится благодаря сетевому эффекту.

I> Подробнее о культуре разработки в Unix и Linux вы узнаете из книги [Эрика Реймонда "Искусство программирования в Unix"](https://ru.wikipedia.org/wiki/Философия_Unix#Реймонд:_Искусство_программирования_в_Unix).