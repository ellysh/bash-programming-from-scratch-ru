## Операционные системы

### Предпосылки возникновения ОС

Большинство пользователей компьютера понимает, зачем нужна [**операционная система**](https://ru.wikipedia.org/wiki/Операционная_система#Функции) (ОС). Покупая или загружая из интернета приложение, вы проверяете его системные требования. В них указаны минимальные параметры аппаратной части компьютера. Кроме этого в требованиях указана ОС.

Получается, что ОС — это программная платформа на которой работают приложения. Но откуда взялось это требование? Почему нельзя просто купить компьютер и запустить на нём приложение без ОС?

Эти вопросы кажутся бессмысленными только на первый взгляд. Подумайте сами: современные ОС универсальны и предлагают пользователю множество функций. Большинство из них каждому конкретному пользователю не нужно. Но эти функции зачастую невозможно отключить. Для их обслуживания ОС активно использует ресурсы компьютера. В результате приложениям пользователя достаётся меньше ресурсов. Из-за этого они работают медленно и зависают.

Обратимся к истории, чтобы выяснить назначение ОС. Первая коммерческая ОС [GM-NAA I/O](https://ru.wikipedia.org/wiki/GM-NAA_I/O) появилась только в 1956 году для компьютера [IBM 704](https://ru.wikipedia.org/wiki/IBM_704). Все ранние модели компьютеров обходились без ОС. Почему в них не было необходимости?

Главная причина заключается в быстродействии. Для примера рассмотрим первый [**электромеханический компьютер**](http://chernykh.net/content/view/16/40/). Его сконструировал [Герман Холлерит](https://ru.wikipedia.org/wiki/Холлерит,_Герман) в 1890 году. Компьютер получил название табулятор. Для работы ему не нужна ОС и [программы](https://ru.wikipedia.org/wiki/Компьютерная_программа) в современном смысле этих терминов. Табулятор выполняет ограниченный набор арифметических операций. Эти операции определяет конструкция компьютера. Данные для вычислений загружаются с [**перфокарт**](https://ru.wikipedia.org/wiki/Перфокарта). Перфокарты представляют собой листки плотной бумаги с пробитыми отверстиями. Оператор компьютера вручную подготавливает и укладывает эти листки в специальные приёмные устройства. Там они нанизываются на иглы. В местах отверстий иглы соприкасаются и электрическая цепь замыкается. Каждое замыкание увеличивает механический счётчик. Счётчиком служит вращающийся цилиндр. Результаты вычислений выводятся на циферблаты, напоминающие часы.

Иллюстрация 1-1 демонстрирует табулятор, построенный Германом Холлеритом.

{caption: "Иллюстрация 1-1. Табулятор Холлерита", height: "30%"}
![Табулятор Холлерита](images/GeneralInformation/tabulating-machine.jpg)

По современным меркам вычисления на табуляторе выполняются очень медленно. Первая причина заключается в ручном обслуживании. Оператор должен самостоятельно пробить перфокарты. Во времена табулятора не было способа делать это автоматически. Далее надо загрузить перфокарты в приёмное устройства и выгрузить их по окончании работы. На эти действия уходило много времени.

Вторая причина медленной работы табулятора связана с конструкцией. Большая часть его деталей механическая: иглы для считывания данных, счётчики из вращающихся цилиндров, циферблаты для вывода результата. Вся эта механика работает медленно. Выполнение одной элементарной операции занимает порядка одной секунды. Никакая автоматизация не способна ускорить такой процесс вычисления.

Для вычислений табулятор использует вращающиеся цилиндры. Их заменили на [**реле**](https://ru.wikipedia.org/wiki/Реле) в компьютерах следующего поколения. Реле — это электромеханический элемент. Он меняет своё состояние под воздействием электрического тока.

Один из [первых релейных компьютеров](https://habr.com/ru/company/ua-hosting/blog/386247) Z2 сконструировал немецкий инженер [Конрад Цузе](https://ru.wikipedia.org/wiki/Цузе,_Конрад) в 1939 году. Этот компьютер был усовершенствован в 1941 году и получил название Z3. Переход на реле сократил время выполнения одной элементарной операции до нескольких миллисекунд.

Кроме возросшей скорости вычислений, компьютеры Цузе отличает ещё одна особенность. В них появилось понятие программы. Теперь на перфокартах пробивались не исходные данные задачи, а [**алгоритм**](https://ru.wikipedia.org/wiki/Алгоритм) её решения. Для ввода данных использовалась клавиатура. Её конструкция отдалённо напоминает печатную машинку.

I> Алгоритмом — это конечная последовательность инструкций для выполнения какого-либо вычисления или решения задачи.

Компьютеры с возможностью ввода алгоритмов стали известны как [**программируемые**](https://ru.wikipedia.org/wiki/Компьютер_общего_назначения) или универсальные.

Появление программируемых компьютеров стало важным шагом в развитии вычислительной техники. Машины предыдущих поколений выполняли только узкоспециализированные задачи. Их создание обходилось дорого и редко себя оправдывало. Поэтому проекты по конструированию компьютеров не привлекали инвесторов. Такие проекты ограничивались военными разработками в годы Второй мировой войны. Новые универсальные компьютеры заинтересовали бизнес.

Следующим шагом развития компьютеров стало создание [**ENIAC**](https://ru.wikipedia.org/wiki/ЭНИАК) (см. иллюстрацию 1-2). Его сконструировала группа инженеров под руководством [Джона Эккерта](https://ru.wikipedia.org/wiki/Эккерт,_Джон_Преспер) и [Джона Мокли](https://ru.wikipedia.org/wiki/Мокли,_Джон) в 1946 году. Его рабочими элементами стали не реле, а [**электровакуумные лампы**](https://ru.wikipedia.org/wiki/Электронная_лампа). То есть электромеханические компоненты с большим временем отклика заменили на более быстрые электронные. Это увеличило быстродействие компьютера на порядок. Время выполнения одной элементарной операции сократилось до 200 микросекунд.

{caption: "Иллюстрация 1-2. ENIAC", height: "30%"}
![ENIAC](images/GeneralInformation/eniac.jpg)

В 1940-е годы многие инженеры скептически относились к электровакуумным лампам. Они были не надёжны и потребляли много энергии. Мало кто верил, что сконструированная на них машина вообще сможет работать. ENIAC использовал около 18000 ламп. Они часто выходили из строя. Но между отказами компьютер успешно справлялся с вычислениями. ENIAC убедил многих конструкторов в перспективности ламп.

ENIAC — это программируемый компьютер. В нём алгоритм вычислений задаётся с помощью комбинации переключателей и перемычек на коммутационных панелях. Такое программирование требует много времени и сил. С ней может справиться только группа операторов. На иллюстрации 1-3 изображена одна из панелей для программирования ENIAC.

{caption: "Иллюстрация 1-3. Панель программирования ENIAC", height: "30%"}
![Панель программирования ENIAC](images/GeneralInformation/eniac-programming.jpg)

ENIAC использует перфокарты для ввода исходных данных и вывода результатов. Предыдущие модели компьютеров обрабатывали ввод-вывод аналогично. Но в ENIAC появилась новая возможность. Перфокарты могли хранить промежуточные расчёты. Если исходная задача не решалась сразу из-за высокой сложности, она разбивалась на несколько подзадач. После выполнения каждой подзадачи её результаты выгружались на перфокарты. Затем компьютер перепрограммировался. После этого перфокарты загружались обратно в качестве входных данных.

Опыт эксплуатации ENIAC показал, что производительность компьютера ограничивают все механические операции. Например, ручное перепрограммирование с помощью переключателей и перемычек, а также чтение и пробивание перфокарт. ENIAC обладал небывалой по тем временам производительностью. Но несмотря на это, прикладные задачи решались на нём медленно. Большую часть времени компьютер простаивал, ожидая программы или входных данных. Опыт работы с ENIAC привел к разработке новых средств ввода и вывода данных.

Следующий скачок производительности компьютеров произошёл после перехода с электровакуумных ламп на [**транзисторы**](https://ru.wikipedia.org/wiki/Транзистор). Вместе с усовершенствованными средствами ввода-вывода это привело к более интенсивной эксплуатации компьютеров и их частому перепрограммированию.

С приходом транзисторов вычислительные машины распространились за пределы военных проектов. Их стали использовать крупные банки и корпорации. В результате возросло число и разнообразие запускаемых программ.

Коммерческое использование компьютеров потребовало исключить простой оборудования. Любые задержки в исполнении программ приводили к финансовым потерям. В этом случае покупка компьютера не оправдывала себя.

Чтобы удовлетворить новым требованиям, требовались новые решения. Дольше всего компьютеры простаивали в ожидании переключения между программами. Идея автоматизировать этот процесс пришла к инженерам General Motors и North American Aviation. Они разработали первую операционную систему [**GM-NAA I/O**](https://ru.wikipedia.org/wiki/GM-NAA_I/O) в 1955 году. Эта ОС позволила выполнять программы друг за другом без помощи оператора.

Интенсивное использование компьютеров и разнообразие программ привело к ещё одной проблеме. Загруженная программа определяла доступные возможности аппаратуры. Например, если программа содержит код управления устройствами ввода-вывода, они доступны. В противном случае устройства не работают.

Компании покупали один компьютер и использовали его продолжительное время. При этом загружаемые программы менялись часто, но аппаратура оставалась неизменной. В результате код управления аппаратурой менялся редко. Программисты просто копировали его из одной программы в другую.

Постоянное копирование кода управления устройствами привело к идее создания служебной программы. Она загружалась в память компьютера вместе с основной программой и обеспечивала поддержку оборудования. Постепенно эти служебные программы вошли в состав первых ОС.

Вернёмся к нашему вопросу о необходимости операционных систем. Мы выяснили, что приложения могут работать и без них. Такие программы используются и сегодня. Например, это [**утилиты**](https://ru.wikipedia.org/wiki/Утилита) проверки памяти и разбивки диска, а также некоторые антивирусы. Однако, разработка таких программ требует больше времени и сил. В них приходится включать код для поддержки оборудования, который обычно предоставляет ОС. Разработчики предпочитают использовать возможности ОС. Это уменьшает объём работы и ускоряет выпуск программы.

Современные ОС очень сложны. Кроме поддержки оборудования и запуска программ, они предоставляют много других возможностей. Рассмотрим их подробнее.

### Возможности ОС

Почему мы начали изучать программирование с обсуждения операционных систем? Возможности ОС являются фундаментом для любой программы.

Иллюстрация 1-4 демонстрирует схему взаимодействия ОС с [**прикладными программами**](https://ru.wikipedia.org/wiki/Прикладное_программное_обеспечение) и [**аппаратным обеспечением**](https://ru.wikipedia.org/wiki/Аппаратное_обеспечение). Прикладные программы — это приложения, которые решают задачи пользователя. Примеры приложений: текстовый редактор, калькулятор, браузер. Аппаратным обеспечением называются все электронные и механические компоненты компьютера. Среди этих компонентов клавиатура, монитор, центральный процессор, видеокарта.

{caption: "Иллюстрация 1-4. Схема взаимодействия ОС с программами и аппаратным обеспечением", height: "50%"}
![Схема взаимодействия ОС](images/GeneralInformation/operating-system.png)

Рассмотрим схему. Приложения обращаются к аппаратным ресурсам не напрямую, а через [**системные библиотеки**](https://ru.wikipedia.org/wiki/Библиотека_(программирование)). Эти библиотеки являются частью ОС. Для работы с ними приложение должно следовать строгим правилам. 

[**Интерфейс прикладного программирования**](https://ru.wikipedia.org/wiki/API) определяет правила работы приложения с системными библиотеками. Он также известен как API (Application Programming Interface). 

Интерфейс — это набор соглашений о взаимодействии компонентов информационной системы. Такие соглашения со временем превращаются в стандарты. Например, POSIX стандарт описывает переносимый API для целого семейства ОС. Стандарты важны, поскольку гарантируют совместимость компонентов системы.

Помимо системных библиотек ОС включает в себя [**ядро**](https://ru.wikipedia.org/wiki/Ядро_операционной_системы) и [**драйвера устройств**](https://ru.wikipedia.org/wiki/Драйвер). Они определяют какие возможности аппаратуры доступны приложению. Драйвер — это специальная программа, которая предоставляет доступ к устройству. Когда приложение обращается к системной библиотеке, библиотека перенаправляет запрос в ядро ОС или драйвер. В некоторых случаях библиотека может выполнить запрос самостоятельно.

При обращении к системной библиотеке приложение вызывает одну из её [**функций**](https://ru.wikipedia.org/wiki/Функция_(программирование)). Функция — это фрагмент программы, который выполняет одну задачу. Представьте себе API как набор всех функций, доступных приложению. Кроме этого API определяет следующие аспекты взаимодействия приложения с ОС:

1. Какую операцию выполнит ОС при вызове конкретной системной функции?

2. Какие данные функция ожидает на вход?

3. Какие данные функция вернёт в качестве результата?

Следовать интерфейсу должна как ОС, так и приложение. Например, в документации к API сказано: "ОС создаёт файл при вызове функции X". Не зависимо от версии, ОС всегда должна следовать этому правилу. Оно гарантирует совместимость разных версий приложений и ОС. Такая совместимость невозможна без хорошо документированного и стандартизированного интерфейса.

Мы уже выяснили, что приложения могут работать без ОС. Однако, ОС предлагает готовые решения для работы с аппаратными ресурсами компьютера. Без этих решений разработчики приложений берут на себя работу с оборудованием. Такой подход требует много времени и сил. Представьте всё разнообразие комплектующих современных компьютеров. Приложение должно поддерживать все модели устройств (например, видеокарт). В противном случае оно не заработает у некоторых пользователей.

Рассмотрим возможности, которые предоставляет ОС через API интерфейс. Все электронные и механические компоненты компьютера можно рассматривать как ресурсы. Программы используют эти ресурсы для вычислений. Другими словами аппаратное обеспечение выполняет программы. API отражает возможности оборудования, которые доступны программе. Также интерфейс определяет порядок взаимодействия между несколькими программами и оборудованием.

Например, две программы не могут одновременно записывать данные на [жёсткий диск](https://ru.wikipedia.org/wiki/Жёсткий_диск#Технологии_записи_данных) в одну и ту же область. На это есть две причины:

1. Запись выполняется единственной магнитной головкой жёсткого диска. Она выполняет одну операцию за раз.

2. После записи данных первым приложением их может затереть второе приложение.

Чтобы избежать ошибок при записи, запросы к диску надо упорядочить. Обычно их помещают в очередь и исполняют друг за другом. За это отвечает ОС, а точнее её ядро (см. иллюстрацию 1-4).

В ядре реализован механизм для управления доступом к жёсткому диску. Этот механизм называется [**файловой системой**](https://ru.wikipedia.org/wiki/Файловая_система). Похожим образом ОС упорядочивает доступ ко всем [**периферийным**](https://ru.wikipedia.org/wiki/Периферийное_устройство) и внутренним устройствам компьютера. Этот доступ предоставляют драйвера устройств.

Что такое периферийные устройства, и чем они отличаются от внутренних? К периферийным относятся все устройства, отвечающие за ввод-вывод информации и её постоянное хранение. Вот несколько примеров:

* Клавиатура
* Мышь
* Микрофон
* Монитор
* Колонки
* Жёсткий диск

Внутренние устройства отвечают за обработку информации, то есть непосредственное исполнение программ. К ним относятся:

* [**Центральный процессор**](https://ru.wikipedia.org/wiki/Центральный_процессор) (central processing unit, CPU)
* [**Оперативная память**](https://ru.wikipedia.org/wiki/Оперативная_память) (random-access memory, RAM)
* [**Видеокарта**](https://ru.wikipedia.org/wiki/Видеокарта) (graphics processing unit, GPU)

Доступ к аппаратным ресурсам — это одна из возможностей ОС. Кроме аппаратных есть ещё и программные ресурсы самой ОС. Это повторяющийся код, ставший со временем служебными программами. Впоследствии его оформили в системные библиотеки (см. иллюстрацию 1-4). Некоторые из библиотек обслуживают устройства. Другие выполняют сложные алгоритмы для обработки данными.

Например, у Windows есть компонент под названием [**интерфейс графических устройств**](https://ru.wikipedia.org/wiki/GDI) (Graphical Device Interface или GDI). Он позволяет приложению манипулировать графическими объектами. Используя GDI, разработчики создают пользовательский интерфейс для своих программ.

Системные библиотеки с полезными алгоритмами (например, GDI) являются программными ресурсами ОС. Они устанавливаются на компьютер вместе с ОС и сразу готовы к использованию. Кроме них ОС предоставляет доступ к алгоритмам сторонних приложений и библиотек.

ОС не только управляет ресурсами. Она организует совместную работу запущенных приложений. Запуск приложения — это нетривиальная задача. Её выполняет специальная служебная программа ОС. После запуска приложения, ОС контролирует его выполнение. Если нарушается какое-то ограничение, приложение завершается. Пример нарушения — чтение недоступной памяти. В следующем разделе мы подробно рассмотрим процесс запуска и исполнения программы.

Если ОС многопользовательская, она контролирует доступ к данным. Благодаря этому, каждый пользователь работает только со своими файлами и каталогами.

Подведём итог. ОС выполняет следующие функции:

1. Предоставляет и упорядочивает доступ к аппаратным ресурсам компьютера.

2. Предоставляет программные ресурсы в виде системных библиотек.

3. Запускает приложения, а также отвечает за ввод данных для них и вывод результата.

4. Организует взаимодействие приложений друг с другом.

5. Контролирует доступ пользователей к данным.

Посмотрите внимательно на эти функции ОС. Наверное вы догадались, что без ОС нельзя запустить несколько приложений одновременно. Проблема в том, что их разработчики не знают, в каком сочетании программы будут выполняться. Только ОС имеет достаточно информации, чтобы эффективно распределить ресурсы компьютера в реальном времени.

### Современные ОС

Мы познакомились с основными возможностями ОС. Теперь учтём новые знания и рассмотрим современные ОС. Их функции во многом аналогичны. Основные отличия заключаются в способах реализации этих функций. Эти особенности реализации и решения, которые к ним привели, называются [**архитектурой**](https://ru.wikipedia.org/wiki/Архитектура_программного_обеспечения).

У современных ОС есть две особенности. Они определяют их поведение и способ взаимодействия с пользователем. Речь идёт о многозадачности и графическом интерфейсе. Рассмотрим их подробнее.

#### Многозадачность

Большинство современных ОС [**многозадачны**](https://ru.wikipedia.org/wiki/Многозадачность). Это означает, что они исполняют несколько программ одновременно. Почему это свойство оказалось важным? Системы с этим свойством вытеснили ОС без него.

В 1960-е годы появилась проблема эффективного использования компьютеров. В то время они стоили дорого. Поэтому ценилась каждая минута их работы. Позволить купить себе мейнфрейм могли только крупные компании и университеты. Они считали неприемлемым любой его простой.

Ранние операционные системы исполняли программы друг за другом без задержек. В таких ОС программы и их входные данные подготавливались заранее. Они записывались на устройство хранения (например, магнитную ленту). Эта лента подавалась на устройство чтения компьютера. Он последовательно исполнял программы и выводил их результаты на устройство вывода (например, принтер). Такой режим работы называется [**пакетная обработка**](https://ru.wikipedia.org/wiki/Пакетное_задание) (batch processing). Он экономит время на переключение компьютера с одной задачи на другую.

Пакетная обработка увеличила эффективность использования мейнфреймов. Она автоматизировала загрузку программ и частично исключила из этого процесса человека-оператора. Однако, у системы осталось [**узкое место**](https://ru.wikipedia.org/wiki/Узкое_место). Вычислительная мощность процессоров значительно выросла. Скорость же работы периферийных устройств почти не изменилась. Поэтому CPU часто простаивал, ожидая ввода-вывода данных.

I> Узкое место (bottleneck) — компонент или ресурс информационной системы, который ограничивает её общую производительность или пропускную способность.

Рассмотрим пример. Представьте, что мейнфрейм последовательно выполняет программы. Данные для них считываются с магнитной ленты, а результаты печатаются на принтере. ОС загружает каждую программу и исполняет её инструкции, затем загружает следующую и так далее. Проблема возникает на этапах чтения данных и печати результата. Время доступа к данным на магнитной ленте огромно в масштабах центрального процессора. Между двумя операциями чтения, он успел бы выполнить ряд вычислений. Но он этого не делает. Все ресурсы компьютера использует только программа, загруженная сейчас в память. То же происходит с выводом результатов на печать. Принтер — это чисто механическое устройство. Он работает очень медленно.

Проблема простоя центрального процессора привела к идее [**мультипрограммирования**](https://ru.wikipedia.org/wiki/Мультипрограммирование). Это означает одновременную загрузку сразу нескольких программ в память компьютера. Первая из них выполняется до тех пор, пока доступны все необходимые ей ресурсы. Как только один из ресурсов оказывается занят, выполнение программы останавливается. Например, ей нужны данные, хранящиеся на жёстком диске. Пока контроллер диска читает первую часть данных, он занят и не может обработать запрос на чтение следующей части. В этом случае ОС прекращает выполнение первой программы и переключается на вторую. Она в свою очередь исполняется до конца или до момента, когда нужный ей ресурс окажется занят. После этого опять происходит переключение задач.

Мультипрограммирование стало прототипом многозадачности, которая реализована в современных ОС. Мультипрограммирование хорошо справляется с режимом пакетной обработки. Однако, этот подход распределения нагрузки не подходит для систем с [**интерактивным взаимодействием**](https://ru.wikipedia.org/wiki/Интерактивность). В таких системах действия пользователя являются событиями. Например, нажатие клавиши. Каждое событие обрабатывается сразу. Например, добавление нового символа в текстовый документ. Время отклика системы должно быть минимальным. Иначе пользователь заметит зависания программы.

Проблема мультипрограммирования в том, что момент переключения задач непредсказуем. Это случится только при её завершении программы или её обращении к занятому ресурсу. При это действия пользователя не будут обработаны до момента переключения задач.

Многозадачность решает проблему быстрого отклика при интерактивной работе с компьютером. Способ её реализации постепенно развивался и усложнялся. В современных ОС применяется [**вытесняющая многозадачность**](https://ru.wikipedia.org/wiki/Вытесняющая_многозадачность) с псевдопараллельной обработкой задач. Это означает, что ОС самостоятельно решает, какую программу выполнять в данный момент. При выборе учитываются приоритеты работающих приложений. То есть более приоритетные приложения будут получать аппаратные ресурсы чаще, чем низкоприоритетные. Механизм переключения задач реализован в ядре ОС и называется [**планировщиком задач**](https://ru.wikipedia.org/wiki/Диспетчер_операционной_системы).

Псевдопараллельность обработки означает, что в каждый момент времени выполняется только одна задача. При этом ОС переключается между задачами настолько быстро, что пользователь этого не замечает. Ему кажется, что компьютер выполняет одновременно несколько программ. При это графический интерфейс сразу реагирует на любое действие. Но на самом деле, каждая программа и компонент ОС получают аппаратные ресурсы в строго определённые моменты времени.

Одновременное выполнение программ возможно только на компьютерах с несколькими процессорами или с [многоядерными](https://ru.wikipedia.org/wiki/Ядро_микропроцессора) процессорами. На таких компьютерах число одновременно работающих программ примерно равно числу ядер всех процессоров. При этом всё равно работает механизм вытесняющей многозадачности с постоянным переключением задач. Он универсален и балансирует нагрузку на любых системах, независимо от числа ядер. Так выдерживается приемлемое время отклика на действия пользователя.

#### Интерфейс пользователя

Современные ОС решают разные задачи. Эти задачи определяет тип компьютера, на котором запускается ОС. Основные типы следующие:

* [Персональные компьютеры](https://ru.wikipedia.org/wiki/Персональный_компьютер) (ПК) и ноутбуки.
* Мобильные телефоны и планшеты.
* Сервера.
* [Встраиваемые системы](https://ru.wikipedia.org/wiki/Встраиваемая_система).

Мы рассмотрим только ОС для ПК и ноутбуков. Помимо многозадачности они предоставляют [**графический интерфейс пользователя**](https://ru.wikipedia.org/wiki/Графический_интерфейс_пользователя) (graphical user interface или GUI). В данном случе интерфейс — это способ взаимодействия с системой. Через него пользователь запускает приложения, настраивает устройства компьютера и компоненты ОС. Рассмотрим подробнее историю возникновения графического интерфейса.

Пользователи коммерческих компьютеров впервые узнали об интерактивном режиме работы в 1960 году. Его поддерживал новый [мини-компьютер](https://ru.wikipedia.org/wiki/Мини-компьютер) [PDP-1](https://ru.wikipedia.org/wiki/PDP-1) от компании [Digital Equipment Corporation](https://ru.wikipedia.org/wiki/Digital_Equipment_Corporation). Почему производители и пользователи компьютеров вообще заинтересовались интерактивностью? В 1950-е годы на рынке мейнфреймов доминировали компьютеры IBM. Они работали в режиме пакетной обработки и хорошо справлялись с вычислительными задачами. Их операционные системы с поддержкой мультипрограммирования автоматизировали загрузку программ и обеспечивали высокую производительность.

Идея интерактивной работы с компьютером появилась в военном проекте SAGE. Он выполнялся по заказу ВВС США. В проекте разрабатывалась автоматизированная система ПВО для обнаружения советских бомбардировщиков. При разработке конструкторы столкнулись с проблемой обработки данных с радаров. Согласно требованиям, компьютер должен был выводить данные в реальном времени. Человек-оператор реагировал на них максимально быстро и отдавал команды. Существующие тогда методы работы с компьютером для этой задачи не подходили. Поскольку в системе ПВО важна скорость реакции на угрозу.

Проект SAGE привёл к созданию первого интерактивного компьютера [AN/FSQ-7](https://en.wikipedia.org/wiki/AN/FSQ-7_Combat_Direction_Central) (см иллюстрацию 1-5). Он выводил данные на [**электронно-лучевой монитор**](https://ru.wikipedia.org/wiki/Кинескоп). Команды вводились оператором с помощью [**светового пера**](https://ru.wikipedia.org/wiki/Световое_перо).

{caption: "Иллюстрация 1-5. Компьютер AN/FSQ-7"}
![Компьютер AN/FSQ-7](images/GeneralInformation/AN-FSQ-7.jpg)

Метод интерактивной работы с компьютером стал известен в научных кругах. Он быстро набрал популярность. Пакетная обработка успешно справлялась с выполнением программ. Однако, их разработка и отладка была неудобной. Программист писал алгоритм и записывал его на устройство хранения. Дальше разработчик помещал свою задачу в очередь на выполнение на мейнфрейме. Ожидание в очереди занимало часы. Если после исполнения программы обнаруживалась ошибка, программист её исправлял и снова помещал свою задачу в очередь. В результате исправление всех ошибок даже в небольшой программе занимало дни.

В интерактивном режиме работы программист запускает программу, ожидает её завершения и видит на экране результат. Это в разы увеличивает скорость разработки и отладки приложений. Теперь работа, требующая несколько дней с пакетной обработкой, выполнялась за несколько часов.

Интерактивный режим принёс новые задачи. Этот режим имел смысл, только если система сразу реагировала на действия пользователя. Для этого требовался новый механизм балансирования нагрузки. С этим требованием справился режим многозадачности новых ОС.

Интерактивный режим поддерживают не только многозадачные ОС, но и однозадачные. Пример такой ОС — [MS-DOS](https://ru.wikipedia.org/wiki/MS-DOS). Совмещение интерактивности и однозадачности было нецелесообразно во времена дорогих мейнфреймов. Тогда ресурсами одного компьютера пользовались сразу несколько пользователей. Их программы исполнялись параллельно и независимо друг от друга. Такой режим работы получил название [**разделение времени**](https://ru.wikipedia.org/wiki/Разделение_времени) (time-sharing). Совместить же однозадачность и разделение времени невозможно.

Когда появились первые относительно дешевые персональные компьютеры, на них устанавливались однозадачные ОС. Они требовали меньше аппаратных ресурсов чем их старшие аналоги для мейнфреймов. Несмотря на свою простоту, однозадачные ОС поддерживали интерактивную работу. Для пользователей ПК этот режим стал особенно привлекательным.

Интерактивный режим поставил не только задачу балансировки нагрузки системы. Нужны были новые способы взаимодействия пользователя и компьютера. Существующие в 1960-е годы магнитные ленты и принтеры для этого не подходили. 

[**Телетайп**](https://ru.wikipedia.org/wiki/Телетайп) (teletype) стал прототипом устройства для интерактивной работы с компьютером. Иллюстрация 1-6 демонстрирует телетайп Model 33. Он представляет собой электромеханическую печатную машинку. С помощью проводов она подключается к такой же машинке. После соединения двух телетайпов операторы могут передавать друг другу текстовые сообщения. Отправитель набирает текст на своём устройстве. Нажатия клавиш передаются на устройство получателя. Оно печатает каждую принятую букву на бумаге.

{caption: "Иллюстрация 1-6. Телетайп Model 33", height: "50%"}
![Телетайп Model 33](images/GeneralInformation/teletype.jpg)

Телетайпы стали подключать к мейнфреймам. Такое устройство называлось [**терминалом**](https://ru.wikipedia.org/wiki/Компьютерный_терминал). На его клавиатуре пользователь набирал команды. Мейнфрейм их получал, исполнял и отправлял результат обратно. Терминал распечатывал полученные данные на бумаге. Позднее устройство печати заменил монитор. В результате получился [**интерфейс командной строки**](https://ru.wikipedia.org/wiki/Интерфейс_командной_строки) (command-line interface или CLI). Принцип его работы напоминает телетайп. Пользователь вводит команды одну за другой. Компьютер последовательно их исполняет и выводит на экран результаты.

Иллюстрация 1-7 демонстрирует современный интерфейс командной строки. Это окно [**эмулятора терминала**](https://ru.wikipedia.org/wiki/Эмулятор_терминала) [Terminator](https://en.wikipedia.org/wiki/Terminator_(terminal_emulator)). В нём запущен интерпретатор командной строки Bash. В окне выведены результаты работы программ ping и ls.

{caption: "Иллюстрация 1-7. Интерфейс командной строки", height: "50%"}
![Интерфейс командной строки](images/GeneralInformation/cli.png)

Интерфейс командной строки востребован и сегодня. Он имеет ряд преимуществ по сравнению с графическим интерфейсом. Главное достоинство CLI в его нетребовательности к вычислительным ресурсам. Он работает одинаково стабильно и без задержек как на низкопроизводительных встраиваемых компьютерах, так и на мощных серверах. Если применять CLI для удалённого доступа к компьютеру, качество канала связи и его пропускная способность могут быть низкими. Даже с медленным соединением сервер получит команды.

У интерфейса командной строки есть и недостатки. Главная его проблема в сложности освоения. Пользователю доступны сотни команд с различными входными параметрами, которые определяют их режим работы. Требуется немало времени, чтобы запомнить хотя бы часто используемые команды.

Проблему наглядного представления доступных команд решил [**текстовый интерфейс пользователя**](https://ru.wikipedia.org/wiki/Текстовый_интерфейс_пользователя) (textual user interface или TUI). В нём наряду с буквенными и цифровыми символами используется [**псевдографика**](https://ru.wikipedia.org/wiki/Псевдографика). Псевдографикой называются специальные символы, с помощью которых на экране отображаются графические примитивы. Примитивы — это линии, прямоугольники, треугольники и т.д. Иллюстрация 1-8 демонстрирует типичный текстовый интерфейс. Это вывод статистики использования системных ресурсов программой htop.

{caption: "Иллюстрация 1-8. Текстовый интерфейс пользователя", height: "50%"}
![Текстовый интерфейс пользователя](images/GeneralInformation/tui.png)

Дальнейший рост производительности компьютеров позволил заменить псевдографику на реальные графические элементы. Примеры таких элементов: окна, иконки, кнопки и т.д. В результате возник полноценный графический интерфейс. Он применяется в современных ОС.

Графический интерфейс ОС Windows приведён на иллюстрации 1-9. Это скриншот рабочего стола. На нём развёрнуты окна трёх приложений: Проводник, Блокнот и Калькулятор. Они работают одновременно.

{caption: "Иллюстрация 1-9. Графический интерфейс пользователя"}
![Графический интерфейс пользователя](images/GeneralInformation/gui.png)

Первый графический интерфейс предназначался для мини-компьютера [Xerox Alto](https://ru.wikipedia.org/wiki/Xerox_Alto) (см. иллюстрацию 1-10). Его разработали в 1973 году в исследовательском центре [Xerox PARC](https://ru.wikipedia.org/wiki/Xerox_PARC). Однако, интерфейс не получил широкого распространения вплоть до 1980-х годов. Он требовал много памяти и высокой производительности компьютера. В то время такие ПК стоили слишком дорого для рядовых пользователей.

Компания Apple выпустила на рынок первый ПК Lisa с графическим интерфейсом только в 1983 году.

{caption: "Иллюстрация 1-10. Мини-компьютер Xerox Alto", height: "50%"}
![Мини-компьютер Xerox Alto](images/GeneralInformation/xerox-alto.jpg)

#### Семейства ОС

Сегодня на рынке персональных компьютеров доминируют три семейства ОС:

* [Windows](https://ru.wikipedia.org/wiki/Windows)
* [Linux](https://ru.wikipedia.org/wiki/Linux)
* [macOS](https://ru.wikipedia.org/wiki/MacOS)

Термин "семейство" означает ряд версий ОС, которые следуют одним и тем же архитектурным решениям. Кроме того большинство функций в этих версиях ОС реализованы одинаково.

Разработчики ОС придерживаются одной и той же архитектуры. Они не предлагают что-то принципиально новое в следующих версиях своего продукта. Почему?

На самом деле изменения в современных ОС происходят, но постепенно и медленно. Причина этого в [**обратной совместимости**](https://ru.wikipedia.org/wiki/Обратная_совместимость). Такая совместимость означает, что новые версии ОС повторяют функции старых версий. Эти функции нужны для работы существующих программ. На первый взгляд это требование кажется необязательным. Но это серьёзное ограничение для разработки программного обеспечения. Давайте разберёмся, почему это так.

Представьте, что вы написали программу для Windows и продаёте её. Иногда пользователи обнаруживают в программе ошибки. Вы их исправляете. Время от времени вы добавляете новые функции.

Теперь представьте, что вышла новая версия Windows. На ней ваша программа не работает. У ваших пользователей есть два решения: 

* Ждать обновления вашей программы, которое совместимо с новой Windows.

* Отказаться от обновления Windows.

Если ваша программа нужна пользователям для ежедневной работы, они откажутся от обновления Windows.

Предположим, что новая Windows принципиально отличается от предыдущей. Это значит, что вашу программу придётся полностью переписать. Посчитайте всё время, которое вы уже потратили на исправление ошибок и добавление новых функций. Эту работу в полном объёме придётся повторить. Скорее всего вы откажетесь от этой идеи и предложите пользователям оставаться на старой версии Windows.

Таких программ как ваша много. Их разработчики придут к тому же решению, что и вы. В результате новая версия Windows окажется никому не нужна. В этом суть проблемы обратной совместимости. Из-за неё и существуют семейства ОС.

Влияние приложений на развитие ОС велико. Например, ОС Windows и персональные компьютеры от IBM обязаны своим успехом табличному процессору [Lotus 1-2-3](https://ru.wikipedia.org/wiki/Lotus_1-2-3). Он запускался только на ПК от IBM с ОС Windows. Ради Lotus 1-2-3 пользователи покупали и ПК, и ОС. Такие популярные приложения, выводящие платформу на широкий рынок, получили название [**killer application**](https://ru.wikipedia.org/wiki/Killer_application) (букв. убойное приложение).

Похожее влияние оказал табличный процессор [VisiCalc](https://ru.wikipedia.org/wiki/VisiCalc). Он содействовал распространению компьютеров [Apple II](https://ru.wikipedia.org/wiki/Apple_II). Точно так же бесплатные компиляторы языков C, Fortran и Pascal подогрели интерес к Unix в университетских кругах. За каждой из трёх доминирующих сегодня ОС стоит killer application. Далее эти ОС распространялись, благодаря [сетевому эффекту](https://ru.wikipedia.org/wiki/Сетевой_эффект). Разработчики новых приложений выбирали программную платформу, которая уже была у большинства пользователей.

Вернёмся к списку семейств ОС. Windows и Linux примечательны тем, что не привязаны к конкретной аппаратной платформе. Это значит, что вы без проблем установите их на любой персональный компьютер или ноутбук. macOS же запускается только на устройствах Apple. Чтобы установить macOS на другую аппаратную платформу, понадобится неофициальная [модифицированная версия](https://ru.wikipedia.org/wiki/OSx86) ОС.

Совместимость с аппаратной платформой — это пример архитектурного решения. Таких решений много. Все вместе они определяют особенности каждого семейства.

ОС определяет инфраструктуру, доступную программисту. Она диктует инструменты разработки. Например, IDE, компилятор, система сборки. Также ОС навязывает архитектурные решения самим приложениям. Принято говорить о сложившейся культуре написания программ под конкретную ОС. Это важный момент: под разные ОС программы принято разрабатывать по-разному. Постарайтесь его учитывать.

Рассмотрим различие культур разработки программ на примере Windows и Linux.

#### Windows

Windows — это [проприетарная](https://ru.wikipedia.org/wiki/Проприетарное_программное_обеспечение) ОС. Исходные коды проприетарных программ закрыты. Вы не сможете их прочитать и изменить. Другими словами нет законного способа узнать про такое ПО больше, чем расскажет его документация.

Чтобы установить Windows на компьютер, вы должны купить её у компании Microsoft. Однако, эта ОС часто предустанавливается на новые компьютеры и ноутбуки. Поэтому её цена включена в конечную стоимость устройства.

Целевой платформой Windows были и остаются относительно дешёвые ПК и ноутбуки. Многие могут позволить себе купить такое устройство. Поэтому рынок потенциальных пользователей огромен. Microsoft стремится сохранить конкурентное преимущество на этом рынке. Компания опасается появления аналогов Windows с такими же возможностями. Microsoft заботится о защите своей интеллектуальной собственности не только техническими, но и юридическими путями. Например, пользовательское соглашение запрещает вам исследовать внутреннее устройство ОС.

Для семейства Windows было написано много прикладных программ. Первые приложения разработала сама компания Microsoft. Например, это пакет офисных приложений [Microsoft Office](https://ru.wikipedia.org/wiki/Microsoft_Office) и [стандартные приложения Windows](https://ru.wikipedia.org/wiki/Категория:Стандартные_приложения_Windows). Для сторонних разработчиков они стали образцом для подражания.

Microsoft придерживалась одного и того же принципа, разрабатывая и ОС, и приложения для неё. Это принцип закрытости: исходные коды недоступны пользователям, форматы данных недокументированны, сторонние утилиты не имеют доступа к возможностям ПО. Эти решения защищают интеллектуальную собственность Microsoft.

Разработчики программ последовали примеру Microsoft. Они придерживались той же философии закрытости. В результате их приложения получались самодостаточными и независимы друг от друга. Форматы их данных закодированы и недокументированны.

Если вы опытный пользователь компьютера, то сразу узнаете типичное Windows-приложение. Это окно с [элементами интерфейса](https://ru.wikipedia.org/wiki/Элемент_интерфейса) вроде кнопок, полей ввода, вкладок и т.д. В этом окне пользователь манипулирует данными. Например, это текст, изображение или звуковая запись. Результат работы сохраняется на жёсткий диск. Его можно открыть снова в этом же приложении. Если вы напишете собственную Windows-программу, она будет выглядеть и работать похожим образом. Такая преемственность решений и называется культурой разработки под ОС.

#### Linux

Linux заимствовал идеи и решения ОС [Unix](https://ru.wikipedia.org/wiki/Unix). Обе ОС следуют набору стандартов [POSIX](https://ru.wikipedia.org/wiki/POSIX) (Portable Operating System Interface). POSIX определяет интерфейсы взаимодействия прикладных программ с ОС. Следование Linux и Unix одному стандарту привело к их похожему поведению.

ОС Unix возникла в конце 1960-х годов. Её создали два инженера из компании Bell Labs. Это был хобби-проект [Кена Томпсона](https://ru.wikipedia.org/wiki/Томпсон,_Кен) и [Денниса Ритчи](https://ru.wikipedia.org/wiki/Ритчи,_Деннис). В рабочее время они разрабатывали ОС [**Multics**](https://ru.wikipedia.org/wiki/Multics). Это был совместный проект Массачусетского технологического института (MIT), компании General Electric (GE) и Bell Labs. Multics планировалась как ОС для нового мейнфрейма GE-645 (см. иллюстрацию 1-11) компании General Electric. 

{caption: "Иллюстрация 1-11. Мейнфрейм модели GE-645", height: "30%"}
![Мейнфрейм модели GE-645](images/GeneralInformation/ge-645.jpg)

В Multics разработчики применили несколько инновационных решений. Одно из них — это разделение времени. То есть мейнфрейм GE-645 стал первым компьютером, на котором одновременно могли работать несколько пользователей. При этом за разделение ресурсов между ними отвечала многозадачность.

ОС Multics оказалась слишком сложной. На её разработку потребовалось больше времени и денег, чем планировалось изначально. Поэтому компания Bell Labs решила выйти из проекта. Но проект был интересен с технической стороны. Поэтому многие инженеры Bell Labs хотели продолжать работу над ним. На этой волне Кен Томпсон решил создать собственную ОС для компьютера GE-645. Он начал писать ядро системы и продублировал некоторые механизмы Multics. Однако, General Electric скоро потребовала вернуть свой GE-645. Ведь Bell Labs получила его только во временное пользование. В результате Кен Томпсон остался без аппаратной платформы для разработки.

Параллельно с работой над аналогом Multics Кен писал компьютерную игру [Space Travel](https://ru.wikipedia.org/wiki/Space_Travel). Она запускалась на мейнфрейме General Electric прошлого поколения GE-635. Этот компьютер работал под управлением ОС [GECOS](https://ru.wikipedia.org/wiki/GCOS). GE-635 представлял собой шкафы с электроникой и стоил около 7 500 000$. Его активно использовали инженеры Bell Labs. Поэтому Кен редко мог с ним работать.

Кен решил портировать свою игру на относительно недорогой и реже используемый коллегами мини-компьютер [PDP-7](https://ru.wikipedia.org/wiki/PDP-7) (см. иллюстрацию 1-12). Он стоил около 72 000$. Но возникла одна проблема. Игра Space Travel использовала возможности ОС GECOS. ОС PDP-7 их не предоставляла. К Кену присоединился коллега Деннис Ритчи. Вмести они реализовали возможности GECOS для PDP-7. Это был набор библиотек и систем. Со временем они развились в самостоятельную ОС Unix.

{caption: "Иллюстрация 1-12. Мини-компьютер PDP-7", height: "30%"}
![Мини-компьютер PDP-7](images/GeneralInformation/pdp-7.jpg)

Кен и Деннис не собирались продавать свои разработки. Поэтому вопроса о защите интеллектуальной собственности никогда не стояло. Они писали Unix для собственных нужд и распространяли её с открытым исходным кодом. Все желающие могли скопировать и использовать ОС в своих проектах. Изначально круг пользователей ограничивался сотрудниками компании Bell Labs. Позднее AT&T, которой принадлежала Bell Labs, предоставила исходный код ОС высшим учебным заведениям США. Таким образом развитие Unix продолжилось уже в университетских кругах.

ОС Linux создал [Линус Торвальдс](https://ru.wikipedia.org/wiki/Торвальдс,_Линус) в 1991 году. В это время он учился в Хельсинкском университете. Линус решал чисто практическую проблему. Ему нужна была полноценная Unix-совместимая ОС для ПК, которой в то время не было.

В Хельсинкском университете студенты выполняли учебные задания на мини-компьютере MicroVAX под управлением Unix. Дома у них были ПК, но Unix на них не запускалась. Для домашнего использования у Unix была альтернатива. Это ОС [Minix](https://ru.wikipedia.org/wiki/Minix), которую разработал Эндрю Таненбаумом в 1987 году для IBM ПК с процессорами Intel 80268. Minix создавалась исключительно для учебных целей. Поэтому Эндрю отказывался вносить в неё изменения для поддержки более современных компьютеров. Эти изменения привели бы к усложнению системы и сделали бы её непригодной для обучения студентов.

Линус задался целью написать Unix-совместимую ОС для своего нового компьютера IBM с процессором Intel 80386. Её прототипом стала Minix. Как и у создателей Unix, у него не было коммерческих интересов и продавать результаты своего труда он не собирался. Линус разрабатывал ОС для собственных нужд и свободно делился ею со всеми желающими. Так получилось, что Linux стала бесплатной. Она свободно распространялась с исходным кодом через интернет.

На самом деле Linux — это только ядро ОС. Оно предоставляет функции для работы с памятью, файловой системой, периферийными устройствами и управлением процессорным временем. Основные функций системы доступны через свободные [пользовательские компоненты GNU](https://ru.wikipedia.org/wiki/Проект_GNU). Эти компоненты разрабатывал [Ричард Столлман](https://ru.wikipedia.org/wiki/Столлман,_Ричард_Мэттью) в Массачусетском технологическом институте. Они тоже распространялись бесплатно. Поэтому Линус включил их в первый [дистрибутив](https://ru.wikipedia.org/wiki/Дистрибутив_Linux) своей ОС.

У первых версий Linux не было графической подсистемы. Пользователь запускал все приложения из командной строки. Только некоторые сложные приложения имели текстовый интерфейс. Со временем в Linux появилась оконная система [X Window System](https://ru.wikipedia.org/wiki/X_Window_System). С её помощью разработчики стали добавлять графический интерфейс своим приложениям.

Культуру написания приложений для Unix и Linux определили условия, в которых развивались эти ОС. Обе системы развивались в университетских кругах. Их пользователями были преподаватели и студенты ИТ специальностей. Они понимали, как работает ОС и охотно вносили в неё свои исправления.

В культуре Unix предпочитают узкоспециализированные утилиты командной строки. Для каждой задачи есть своя утилита. Она хорошо написана, многократно протестирована и работает максимально эффективно. Если решается сложная задача, одна узкоспециализированная утилита не в состоянии с ней справится. Но если скомбинировать несколько утилит, задача решается быстро и эффективно. Поэтому утилиты принимают входные данные и выводят результаты в открытом формате. Как правило, это [текстовые](https://ru.wikipedia.org/wiki/Текстовые_данные) данные. Исходный код утилит всегда доступен для изучения и исправления.

Культура разработки Linux во многом повторяет традиции Unix. Она отличается от стандартов, принятых в Windows. В Windows каждое приложение монолитно и самостоятельно выполняет все свои задачи. Оно не полагается на сторонние утилиты, которые могут оказаться платными или недоступными для пользователя. Каждый разработчик полагается только на себя. Он не в праве требовать от пользователя купить что-то дополнительное для работы его приложения. В Linux же большинство утилит бесплатны, взаимозаменяемы и легко доступны через интернет. Поэтому естественно, что одно приложение потребует загрузить и установить недостающие ему системные компоненты или другое приложение.

Взаимодействие программ принципиально важно в Linux. Даже монолитные графические приложения в Linux обычно предоставляют дополнительный интерфейс командной строки. Таким образом они органично вписываются в экосистему и легко интегрируются с другими утилитами и приложениями.

В Linux сложный вычислительный процесс часто строится на сочетании узкоспециализированных программ. Чтобы это было эффективным, нужны средства для составления общего алгоритма вычислений. Именно для этого была создана [командная оболочка](https://ru.wikipedia.org/wiki/Командная_оболочка_Unix) [Bourne shell](https://ru.wikipedia.org/wiki/Bourne_shell) и её потомок [Bash](https://ru.wikipedia.org/wiki/Bash). В этой книге мы рассмотрим только Bash. Он вытеснил Bourne shell на всех современных Linux-системах.

Нельзя отдать однозначное предпочтение культуре Linux или Windows. Их сравнение давно служит поводом для бесконечных споров. Каждая из культур имеет свои достоинства и недостатки. Например, типичные для Windows монолитные приложения лучше справляются с задачами, требующими интенсивных расчётов. При комбинации узкоспециализированных Linux-утилит в этом случае появляются накладные расходы. Они связаны с запуском утилит и передачей данных между ними. Всё это требует дополнительного времени. В результате задача выполняется дольше.

Сегодня происходит синтез культур Windows и Linux. Всё больше коммерческих приложений портируются на Linux: браузеры, инструменты для разработки программ, игры, мессенджеры и т.д. При этом их разработчики часто не готовы вносить изменения, продиктованные Linux-культурой. Такие изменения требуют времени и сил. Кроме того они усложняют сопровождение продукта. Вместо одного приложения получается два: под каждую платформу разная версия. Намного проще портировать приложение в том же виде, в каком оно уже работает под Windows. В результате под Linux всё чаще встречаются приложения, выполненные в типичном Windows-стиле. О плюсах и минусах этого процесса можно спорить. Но одно очевидно: чем больше приложений запускается на ОС, тем популярнее она становится благодаря сетевому эффекту.

I> Подробнее о культуре разработки в Unix и Linux вы узнаете из книги [Эрика Реймонда "Искусство программирования в Unix"](https://ru.wikipedia.org/wiki/Философия_Unix#Реймонд:_Искусство_программирования_в_Unix).